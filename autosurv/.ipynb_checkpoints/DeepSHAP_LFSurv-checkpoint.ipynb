{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fd6050-07c7-4222-bacb-b69fb5a18f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import lifelines\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from LFSurv import LFSurv\n",
    "from utils import sort_data, splitExprandSample\n",
    "\n",
    "dtype = torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de974d9-16fc-4ab1-bd12-00f20ee950b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we implement DeepSHAP on the CPU and we do not convert the loaded variables into .cuda() form\n",
    "\"\"\"\n",
    "\n",
    "def load_data(path, dtype):\n",
    "    patient_id, x, ytime, yevent, age, stage_i, stage_ii, race_white = sort_data(path)\n",
    "    X = torch.from_numpy(x).type(dtype)\n",
    "    YTIME = torch.from_numpy(ytime).type(dtype)\n",
    "    YEVENT = torch.from_numpy(yevent).type(dtype)\n",
    "    AGE = torch.from_numpy(age).type(dtype)\n",
    "    STAGE_I = torch.from_numpy(stage_i).type(dtype)\n",
    "    STAGE_II = torch.from_numpy(stage_ii).type(dtype)\n",
    "    RACE_WHITE = torch.from_numpy(race_white).type(dtype)\n",
    "    \n",
    "    return(patient_id, X, YTIME, YEVENT, AGE, STAGE_I, STAGE_II, RACE_WHITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6921fd94-af81-4aa7-9f79-dee20627c8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prognosis_index_training size: 857, prognosis_index_testing size: 201.\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "patient_id_train_overall, x_train_overall, ytime_train_overall, yevent_train_overall, age_train_overall, stage_i_train_overall, stage_ii_train_overall, race_white_train_overall = load_data(\"tr_z_2omics.csv\", dtype)\n",
    "patient_id_test_overall, x_test_overall, ytime_test_overall, yevent_test_overall, age_test_overall, stage_i_test_overall, stage_ii_test_overall, race_white_test_overall = load_data(\"tes_z_2omics.csv\", dtype)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Initialize the LFSurv network using the optimal set of hyperparameters\n",
    "\"\"\"\n",
    "net = LFSurv(8, 32, 0.5, 0.1)\n",
    "\"\"\"\"\"\"\n",
    "net.load_state_dict(torch.load(\"saved_models/sup_checkpoint_overall.pt\", map_location=torch.device('cpu')))\n",
    "\n",
    "\"\"\"\n",
    "Get prognostic indicies for the tuning set and testing set patients, respectively.\n",
    "\"\"\"\n",
    "net.eval()\n",
    "train_y_pred = net(x_train_overall, age_train_overall, stage_i_train_overall, stage_ii_train_overall, race_white_train_overall, s_dropout = False)\n",
    "test_y_pred = net(x_test_overall, age_test_overall, stage_i_test_overall, stage_ii_test_overall, race_white_test_overall, s_dropout = False)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "prognosis_index_train = train_y_pred\n",
    "prognosis_index_test = test_y_pred\n",
    "\n",
    "print(\"Prognosis_index_training size: %s,\" %prognosis_index_train.size()[0], \"prognosis_index_testing size: %s.\" %prognosis_index_test.size()[0])\n",
    "\n",
    "processed_tr_pre = torch.cat((ytime_train_overall, yevent_train_overall, age_train_overall, stage_i_train_overall, stage_ii_train_overall, race_white_train_overall, x_train_overall, prognosis_index_train), 1)\n",
    "processed_tes_pre = torch.cat((ytime_test_overall, yevent_test_overall, age_test_overall, stage_i_test_overall, stage_ii_test_overall, race_white_test_overall, x_test_overall, prognosis_index_test), 1)\n",
    "\n",
    "z_count = np.array(list(range(1, x_train_overall.size()[1]+1, 1))).astype('str')\n",
    "z_names = np.char.add('Z_', z_count).tolist()\n",
    "\n",
    "processed_tr = pd.DataFrame(processed_tr_pre.detach().numpy(), columns = ['OS.time', 'OS', 'age', 'stage_i', 'stage_ii', 'race_white'] + z_names + [\"Prognosis_index\"])\n",
    "processed_tr = processed_tr.astype(float)\n",
    "processed_tr = pd.concat([patient_id_train_overall, processed_tr], axis=1)\n",
    "\n",
    "processed_tes = pd.DataFrame(processed_tes_pre.detach().numpy(), columns = ['OS.time', 'OS', 'age', 'stage_i', 'stage_ii', 'race_white'] + z_names + [\"Prognosis_index\"])\n",
    "processed_tes = processed_tes.astype(float)\n",
    "processed_tes = pd.concat([patient_id_test_overall, processed_tes], axis=1)\n",
    "\n",
    "#processed_tr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b387420-04a8-43ba-9e57-1577da8e0fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>null_distribution</th>\n",
       "      <td>chi squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degrees_of_freedom</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_name</th>\n",
       "      <td>logrank_test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_statistic</th>\n",
       "      <th>p</th>\n",
       "      <th>-log2(p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.78</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>29.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{tabular}{lrrr}\n",
       " & test_statistic & p & -log2(p) \\\\\n",
       "0 & 36.78 & 0.00 & 29.49 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "<lifelines.StatisticalResult: logrank_test>\n",
       "               t_0 = -1\n",
       " null_distribution = chi squared\n",
       "degrees_of_freedom = 1\n",
       "         test_name = logrank_test\n",
       "\n",
       "---\n",
       " test_statistic      p  -log2(p)\n",
       "          36.78 <0.005     29.49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>null_distribution</th>\n",
       "      <td>chi squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degrees_of_freedom</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_name</th>\n",
       "      <td>logrank_test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_statistic</th>\n",
       "      <th>p</th>\n",
       "      <th>-log2(p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.47</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>14.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{tabular}{lrrr}\n",
       " & test_statistic & p & -log2(p) \\\\\n",
       "0 & 16.47 & 0.00 & 14.30 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "<lifelines.StatisticalResult: logrank_test>\n",
       "               t_0 = -1\n",
       " null_distribution = chi squared\n",
       "degrees_of_freedom = 1\n",
       "         test_name = logrank_test\n",
       "\n",
       "---\n",
       " test_statistic      p  -log2(p)\n",
       "          16.47 <0.005     14.30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Divide patients into high- and low-risk groups according to the median prognostic index among the tuning set patients\n",
    "\"\"\"\n",
    "\n",
    "condition1_tr = processed_tr[\"Prognosis_index\"]>processed_tr[\"Prognosis_index\"].median()\n",
    "condition2_tr = processed_tr[\"Prognosis_index\"]<=processed_tr[\"Prognosis_index\"].median()\n",
    "\n",
    "condition1_tes = processed_tes[\"Prognosis_index\"]>processed_tr[\"Prognosis_index\"].median()\n",
    "condition2_tes = processed_tes[\"Prognosis_index\"]<=processed_tr[\"Prognosis_index\"].median()\n",
    "\n",
    "upper_group_tr = processed_tr[condition1_tr]\n",
    "lower_group_tr = processed_tr[condition2_tr]\n",
    "\n",
    "upper_group_tes = processed_tes[condition1_tes]\n",
    "lower_group_tes = processed_tes[condition2_tes]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Draw Kaplan Meier curves for tuning set and testing set patients, respectively\n",
    "\"\"\"\n",
    "# Tuning set\n",
    "T1_tr=upper_group_tr['OS.time']\n",
    "E1_tr=upper_group_tr['OS']\n",
    "T2_tr=lower_group_tr['OS.time']\n",
    "E2_tr=lower_group_tr['OS']\n",
    "\n",
    "kmf_tr = KaplanMeierFitter()\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax = kmf_tr.fit(T1_tr, E1_tr, label=\"High-risk group\").plot(ax=ax)\n",
    "ax = kmf_tr.fit(T2_tr, E2_tr, label=\"Low-risk group\").plot(ax=ax)\n",
    "\n",
    "# Testing set\n",
    "T1_tes=upper_group_tes['OS.time']\n",
    "E1_tes=upper_group_tes['OS']\n",
    "T2_tes=lower_group_tes['OS.time']\n",
    "E2_tes=lower_group_tes['OS']\n",
    "\n",
    "kmf_tes = KaplanMeierFitter()\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax = kmf_tes.fit(T1_tes, E1_tes, label=\"High-risk group\").plot(ax=ax)\n",
    "ax = kmf_tes.fit(T2_tes, E2_tes, label=\"Low-risk group\").plot(ax=ax)\n",
    "\n",
    "# Log-rank tests for the KM curves\n",
    "# Tuning set\n",
    "results_tr=logrank_test(T1_tr, T2_tr, event_observed_A=E1_tr, event_observed_B=E2_tr)\n",
    "results_tr.print_summary()\n",
    "\n",
    "#Testing set\n",
    "results_tes=logrank_test(T1_tes, T2_tes, event_observed_A=E1_tes, event_observed_B=E2_tes)\n",
    "results_tes.print_summary()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Save the high- and low-risk group patient information\n",
    "\"\"\"\n",
    "\n",
    "upper_group_tr.to_csv(\"saved_models/higher_PI_train.csv\", index=False)\n",
    "lower_group_tr.to_csv(\"saved_models/lower_PI_train.csv\", index=False)\n",
    "upper_group_tes.to_csv(\"saved_models/higher_PI_test.csv\", index=False)\n",
    "lower_group_tes.to_csv(\"saved_models/lower_PI_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "142c6e0d-35b6-4a72-87fb-0226c34c8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DeepSHAP\n",
    "\"\"\"\n",
    "\n",
    "def load_data_deepshap(data, dtype):\n",
    "    z = data.drop([\"patient_id\", \"OS\", \"OS.time\", \"age\", \"race_white\", \"stage_i\", \"stage_ii\", \"Prognosis_index\"], axis = 1).values.astype(np.float)\n",
    "    age = data.loc[:, [\"age\"]].values.astype(np.float)\n",
    "    stage_i = data.loc[:, [\"stage_i\"]].values.astype(np.float)\n",
    "    stage_ii = data.loc[:, [\"stage_ii\"]].values.astype(np.float)\n",
    "    race_white = data.loc[:, [\"race_white\"]].values.astype(np.float)\n",
    "    \n",
    "    Z = torch.from_numpy(z).type(dtype)\n",
    "    AGE = torch.from_numpy(age).type(dtype)\n",
    "    STAGE_I = torch.from_numpy(stage_i).type(dtype)\n",
    "    STAGE_II = torch.from_numpy(stage_ii).type(dtype)\n",
    "    RACE_WHITE = torch.from_numpy(race_white).type(dtype)\n",
    "    \n",
    "    return(Z, AGE, STAGE_I, STAGE_II, RACE_WHITE)\n",
    "\n",
    "def load_feature_deepshap(data):\n",
    "    feature_data = data.drop([\"patient_id\", \"OS\", \"OS.time\", \"Prognosis_index\"], axis = 1)\n",
    "    \n",
    "    return feature_data\n",
    "\n",
    "\"\"\"\n",
    "These codes were adapted from the work of Withnell et al. https://academic.oup.com/bib/article/22/6/bbab315/6353242\n",
    "Please check their original implementation of DeepSHAP for more details at https://github.com/zhangxiaoyu11/XOmiVAE\n",
    "\"\"\"\n",
    "\n",
    "class Explainer(object):\n",
    "    \"\"\" This is the superclass of all explainers.\n",
    "    \"\"\"\n",
    "\n",
    "    def shap_values(self, X):\n",
    "        raise Exception(\"SHAP values not implemented for this explainer!\")\n",
    "\n",
    "    def attributions(self, X):\n",
    "        return self.shap_values(X)\n",
    "\n",
    "class PyTorchDeepExplainer(Explainer):\n",
    "\n",
    "    def __init__(self, model, data, outputNumber, dim, explainLatentSpace):\n",
    "        \n",
    "        data = list(load_data_deepshap(data, dtype))\n",
    "        \n",
    "        # check if we have multiple inputs\n",
    "        self.multi_input = False\n",
    "        if type(data) == list:\n",
    "            self.multi_input = True\n",
    "        else:\n",
    "            data = [data]\n",
    "        self.data = data\n",
    "        self.layer = None\n",
    "        self.input_handle = None\n",
    "        self.interim = False\n",
    "        self.interim_inputs_shape = None\n",
    "        self.expected_value = None  # to keep the DeepExplainer base happy\n",
    "        if type(model) == tuple:\n",
    "\n",
    "            self.interim = True\n",
    "            model, layer = model\n",
    "            model = model.eval()\n",
    "            self.layer = layer\n",
    "            self.add_target_handle(self.layer)\n",
    "\n",
    "            # if we are taking an interim layer, the 'data' is going to be the input\n",
    "            # of the interim layer; we will capture this using a forward hook\n",
    "            with torch.no_grad():\n",
    "                _ = model(*data)\n",
    "                interim_inputs = self.layer.target_input\n",
    "                if type(interim_inputs) is tuple:\n",
    "                    # this should always be true, but just to be safe\n",
    "                    self.interim_inputs_shape = [i.shape for i in interim_inputs]\n",
    "                else:\n",
    "                    self.interim_inputs_shape = [interim_inputs.shape]\n",
    "            self.target_handle.remove()\n",
    "            del self.layer.target_input\n",
    "        self.model = model.eval()\n",
    "        self.multi_output = False\n",
    "        self.num_outputs = 1\n",
    "        with torch.no_grad():\n",
    "            outputs = model(*data)\n",
    "\n",
    "            #This is where specifies whether we want to explain the mean or z output\n",
    "            if type(outputs) != list:\n",
    "                output = outputs\n",
    "            else:\n",
    "                output = outputs[outputNumber]\n",
    "            self.outputNum=outputNumber\n",
    "            # Chosen dimension\n",
    "            self.dim=None\n",
    "            self.explainLatent = False\n",
    "            if explainLatentSpace:\n",
    "                self.explainLatent=True\n",
    "                self.dimension=dim\n",
    "                output = output[:, dim]\n",
    "                output = output.reshape(output.shape[0], 1)\n",
    "            # also get the device everything is running on\n",
    "            self.device = output.device\n",
    "            if output.shape[1] > 1:\n",
    "                self.multi_output = True\n",
    "                self.num_outputs = output.shape[1]\n",
    "            self.expected_value = output.mean(0).cpu().numpy()\n",
    "\n",
    "    def add_target_handle(self, layer):\n",
    "\n",
    "        input_handle = layer.register_forward_hook(get_target_input)\n",
    "        self.target_handle = input_handle\n",
    "\n",
    "    def add_handles(self, model, forward_handle, backward_handle):\n",
    "        \"\"\"\n",
    "        Add handles to all non-container layers in the model.\n",
    "        Recursively for non-container layers\n",
    "        \"\"\"\n",
    "        handles_list = []\n",
    "        model_children = list(model.children())\n",
    "        if model_children:\n",
    "            for child in model_children:\n",
    "                handles_list.extend(self.add_handles(child, forward_handle, backward_handle))\n",
    "        else:  # leaves\n",
    "            handles_list.append(model.register_forward_hook(forward_handle))\n",
    "            handles_list.append(model.register_backward_hook(backward_handle))\n",
    "\n",
    "        return handles_list\n",
    "\n",
    "    def remove_attributes(self, model):\n",
    "        \"\"\"\n",
    "        Removes the x and y attributes which were added by the forward handles\n",
    "        Recursively searches for non-container layers\n",
    "        \"\"\"\n",
    "        for child in model.children():\n",
    "            if 'nn.modules.container' in str(type(child)):\n",
    "                self.remove_attributes(child)\n",
    "            else:\n",
    "                try:\n",
    "                    del child.x\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "                try:\n",
    "                    del child.y\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "\n",
    "    def gradient(self, idx, inputs):\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        X = [x.requires_grad_() for x in inputs]\n",
    "        \n",
    "        output = self.model(*X)\n",
    "\n",
    "        #Specify the output to change\n",
    "        if type(output) != list:\n",
    "            outputs = output\n",
    "        else:\n",
    "            outputs = output[self.outputNum]\n",
    "\n",
    "        #Specify the dimension to explain\n",
    "        if self.explainLatent==True:\n",
    "\n",
    "            outputs = outputs[:, self.dimension]\n",
    "            outputs = outputs.reshape(outputs.shape[0], 1)\n",
    "\n",
    "\n",
    "        selected = [val for val in outputs[:, idx]]\n",
    "\n",
    "        grads = []\n",
    "        if self.interim:\n",
    "            interim_inputs = self.layer.target_input\n",
    "            for idx, input in enumerate(interim_inputs):\n",
    "                grad = torch.autograd.grad(selected, input,\n",
    "                                           retain_graph=True if idx + 1 < len(interim_inputs) else None,\n",
    "                                           allow_unused=True)[0]\n",
    "                if grad is not None:\n",
    "                    grad = grad.cpu().numpy()\n",
    "                else:\n",
    "                    grad = torch.zeros_like(interim_inputs[idx]).cpu().numpy()\n",
    "                grads.append(grad)\n",
    "            del self.layer.target_input\n",
    "            return grads, [i.detach().cpu().numpy() for i in interim_inputs]\n",
    "        else:\n",
    "            for idx, x in enumerate(X):\n",
    "                grad = torch.autograd.grad(selected, x,\n",
    "                                           retain_graph=True if idx + 1 < len(X) else None,\n",
    "                                           allow_unused=True)[0]\n",
    "                if grad is not None:\n",
    "                    grad = grad.cpu().numpy()\n",
    "                else:\n",
    "                    grad = torch.zeros_like(X[idx]).cpu().numpy()\n",
    "                grads.append(grad)\n",
    "            return grads\n",
    "\n",
    "    def shap_values(self, X, ranked_outputs=None, output_rank_order=\"max\", check_additivity=False):\n",
    "\n",
    "        # X ~ self.model_input\n",
    "        # X_data ~ self.data\n",
    "        \n",
    "        X = list(load_data_deepshap(X, dtype))\n",
    "\n",
    "        # check if we have multiple inputs\n",
    "        if not self.multi_input:\n",
    "            assert type(X) != list, \"Expected a single tensor model input!\"\n",
    "            X = [X]\n",
    "        else:\n",
    "            assert type(X) == list, \"Expected a list of model inputs!\"\n",
    "\n",
    "\n",
    "        X = [x.detach().to(self.device) for x in X]\n",
    "\n",
    "        # if ranked output is given then this code is run and only the 'max' value given is explained\n",
    "        if ranked_outputs is not None and self.multi_output:\n",
    "            with torch.no_grad():\n",
    "                model_output_values = self.model(*X)\n",
    "                # Withnell's change to adjust for the additional outputs in VAE model\n",
    "                model_output_values = model_output_values[self.outputNum]\n",
    "\n",
    "            # rank and determine the model outputs that we will explain\n",
    "\n",
    "            if output_rank_order == \"max\":\n",
    "                _, model_output_ranks = torch.sort(model_output_values, descending=True)\n",
    "            elif output_rank_order == \"min\":\n",
    "                _, model_output_ranks = torch.sort(model_output_values, descending=False)\n",
    "            elif output_rank_order == \"max_abs\":\n",
    "                _, model_output_ranks = torch.sort(torch.abs(model_output_values), descending=True)\n",
    "            else:\n",
    "                assert False, \"output_rank_order must be max, min, or max_abs!\"\n",
    "\n",
    "        else:\n",
    "            # outputs and srray of 0s so we know we are explaining the first value\n",
    "            model_output_ranks = (torch.ones((X[0].shape[0], self.num_outputs)).int() *\n",
    "                                  torch.arange(0, self.num_outputs).int())\n",
    "\n",
    "        # add the gradient handles\n",
    "\n",
    "        handles = self.add_handles(self.model, add_interim_values, deeplift_grad)\n",
    "        if self.interim:\n",
    "            self.add_target_handle(self.layer)\n",
    "\n",
    "        # compute the attributions\n",
    "        output_phis = []\n",
    "\n",
    "        for i in range(model_output_ranks.shape[1]):\n",
    "\n",
    "            phis = []\n",
    "            #phis are shapLundberg values\n",
    "\n",
    "            if self.interim:\n",
    "                for k in range(len(self.interim_inputs_shape)):\n",
    "                    phis.append(np.zeros((X[0].shape[0], ) + self.interim_inputs_shape[k][1: ]))\n",
    "            else:\n",
    "                for k in range(len(X)):\n",
    "                    phis.append(np.zeros(X[k].shape))\n",
    "            #shape is 5 as testing 5 samples\n",
    "            for j in range(X[0].shape[0]):\n",
    "\n",
    "                # tile the inputs to line up with the background data samples\n",
    "                tiled_X = [X[l][j:j + 1].repeat(\n",
    "                                   (self.data[l].shape[0],) + tuple([1 for k in range(len(X[l].shape) - 1)])) for l\n",
    "                           in range(len(X))]\n",
    "                joint_x = [torch.cat((tiled_X[l], self.data[l]), dim=0) for l in range(len(X))]\n",
    "                # run attribution computation graph\n",
    "                feature_ind = model_output_ranks[j, i]\n",
    "                sample_phis = self.gradient(feature_ind, joint_x)\n",
    "                # assign the attributions to the right part of the output arrays\n",
    "                if self.interim:\n",
    "                    sample_phis, output = sample_phis\n",
    "                    x, data = [], []\n",
    "                    for i in range(len(output)):\n",
    "                        x_temp, data_temp = np.split(output[i], 2)\n",
    "                        x.append(x_temp)\n",
    "                        data.append(data_temp)\n",
    "                    for l in range(len(self.interim_inputs_shape)):\n",
    "                        phis[l][j] = (sample_phis[l][self.data[l].shape[0]:] * (x[l] - data[l])).mean(0)\n",
    "                else:\n",
    "                    for l in range(len(X)):\n",
    "                        phis[l][j] = (torch.from_numpy(sample_phis[l][self.data[l].shape[0]:]).to(self.device) * (X[l][j: j + 1] - self.data[l])).cpu().numpy().mean(0)\n",
    "            output_phis.append(phis[0] if not self.multi_input else phis)\n",
    "\n",
    "\n",
    "        # cleanup; remove all gradient handles\n",
    "        for handle in handles:\n",
    "            handle.remove()\n",
    "        self.remove_attributes(self.model)\n",
    "        if self.interim:\n",
    "            self.target_handle.remove()\n",
    "\n",
    "        if not self.multi_output:\n",
    "            return output_phis[0]\n",
    "        elif ranked_outputs is not None:\n",
    "            # Withnell: returns a list... only want first value\n",
    "            return output_phis, model_output_ranks\n",
    "        else:\n",
    "            return output_phis\n",
    "\n",
    "# Module hooks\n",
    "\n",
    "\n",
    "def deeplift_grad(module, grad_input, grad_output):\n",
    "    \"\"\"The backward hook which computes the deeplift\n",
    "    gradient for an nn.Module\n",
    "    \"\"\"\n",
    "    # first, get the module type\n",
    "    module_type = module.__class__.__name__\n",
    "\n",
    "    # first, check the module is supported\n",
    "    if module_type in op_handler:\n",
    "\n",
    "        if op_handler[module_type].__name__ not in ['passthrough', 'linear_1d']:\n",
    "            return op_handler[module_type](module, grad_input, grad_output)\n",
    "    else:\n",
    "        print('Warning: unrecognized nn.Module: {}'.format(module_type))\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "def add_interim_values(module, input, output):\n",
    "    \"\"\"The forward hook used to save interim tensors, detached\n",
    "    from the graph. Used to calculate the multipliers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        del module.x\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    try:\n",
    "        del module.y\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    module_type = module.__class__.__name__\n",
    "\n",
    "    if module_type in op_handler:\n",
    "        func_name = op_handler[module_type].__name__\n",
    "\n",
    "        # First, check for cases where we don't need to save the x and y tensors\n",
    "        if func_name == 'passthrough':\n",
    "            pass\n",
    "        else:\n",
    "            # check only the 0th input varies\n",
    "            for i in range(len(input)):\n",
    "                if i != 0 and type(output) is tuple:\n",
    "                    assert input[i] == output[i], \"Only the 0th input may vary!\"\n",
    "            # if a new method is added, it must be added here too. This ensures tensors\n",
    "            # are only saved if necessary\n",
    "            if func_name in ['maxpool', 'nonlinear_1d']:\n",
    "                # only save tensors if necessary\n",
    "                if type(input) is tuple:\n",
    "                    setattr(module, 'x', torch.nn.Parameter(input[0].detach()))\n",
    "                else:\n",
    "                    setattr(module, 'x', torch.nn.Parameter(input.detach()))\n",
    "                if type(output) is tuple:\n",
    "                    setattr(module, 'y', torch.nn.Parameter(output[0].detach()))\n",
    "                else:\n",
    "                    setattr(module, 'y', torch.nn.Parameter(output.detach()))\n",
    "            if module_type in failure_case_modules:\n",
    "                input[0].register_hook(deeplift_tensor_grad)\n",
    "\n",
    "\n",
    "def get_target_input(module, input, output):\n",
    "    \"\"\"A forward hook which saves the tensor - attached to its graph.\n",
    "    Used if we want to explain the interim outputs of a model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        del module.target_input\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    setattr(module, 'target_input', input)\n",
    "\n",
    "# Withnell:\n",
    "# From the documentation: \"The current implementation will not have the presented behavior for\n",
    "# complex Module that perform many operations. In some failure cases, grad_input and grad_output\n",
    "# will only contain the gradients for a subset of the inputs and outputs.\n",
    "# The tensor hook below handles such failure cases (currently, MaxPool1d). In such cases, the deeplift\n",
    "# grad should still be computed, and then appended to the complex_model_gradients list. The tensor hook\n",
    "# will then retrieve the proper gradient from this list.\n",
    "\n",
    "\n",
    "failure_case_modules = ['MaxPool1d']\n",
    "\n",
    "\n",
    "def deeplift_tensor_grad(grad):\n",
    "    return_grad = complex_module_gradients[-1]\n",
    "    del complex_module_gradients[-1]\n",
    "    return return_grad\n",
    "\n",
    "\n",
    "complex_module_gradients = []\n",
    "\n",
    "\n",
    "def passthrough(module, grad_input, grad_output):\n",
    "    \"\"\"No change made to gradients\"\"\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def maxpool(module, grad_input, grad_output):\n",
    "    pool_to_unpool = {\n",
    "        'MaxPool1d': torch.nn.functional.max_unpool1d,\n",
    "        'MaxPool2d': torch.nn.functional.max_unpool2d,\n",
    "        'MaxPool3d': torch.nn.functional.max_unpool3d\n",
    "    }\n",
    "    pool_to_function = {\n",
    "        'MaxPool1d': torch.nn.functional.max_pool1d,\n",
    "        'MaxPool2d': torch.nn.functional.max_pool2d,\n",
    "        'MaxPool3d': torch.nn.functional.max_pool3d\n",
    "    }\n",
    "    delta_in = module.x[: int(module.x.shape[0] / 2)] - module.x[int(module.x.shape[0] / 2):]\n",
    "    dup0 = [2] + [1 for i in delta_in.shape[1:]]\n",
    "    # we also need to check if the output is a tuple\n",
    "    y, ref_output = torch.chunk(module.y, 2)\n",
    "    cross_max = torch.max(y, ref_output)\n",
    "    diffs = torch.cat([cross_max - ref_output, y - cross_max], 0)\n",
    "\n",
    "    # all of this just to unpool the outputs\n",
    "    with torch.no_grad():\n",
    "        _, indices = pool_to_function[module.__class__.__name__](\n",
    "            module.x, module.kernel_size, module.stride, module.padding,\n",
    "            module.dilation, module.ceil_mode, True)\n",
    "        xmax_pos, rmax_pos = torch.chunk(pool_to_unpool[module.__class__.__name__](\n",
    "            grad_output[0] * diffs, indices, module.kernel_size, module.stride,\n",
    "            module.padding, list(module.x.shape)), 2)\n",
    "    org_input_shape = grad_input[0].shape  # for the maxpool 1d\n",
    "    grad_input = [None for _ in grad_input]\n",
    "    grad_input[0] = torch.where(torch.abs(delta_in) < 1e-7, torch.zeros_like(delta_in),\n",
    "                           (xmax_pos + rmax_pos) / delta_in).repeat(dup0)\n",
    "    if module.__class__.__name__ == 'MaxPool1d':\n",
    "        complex_module_gradients.append(grad_input[0])\n",
    "        # the grad input that is returned doesn't matter, since it will immediately be\n",
    "        # be overridden by the grad in the complex_module_gradient\n",
    "        grad_input[0] = torch.ones(org_input_shape)\n",
    "    return tuple(grad_input)\n",
    "\n",
    "\n",
    "def linear_1d(module, grad_input, grad_output):\n",
    "    \"\"\"No change made to gradients.\"\"\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def nonlinear_1d(module, grad_input, grad_output):\n",
    "    delta_out = module.y[: int(module.y.shape[0] / 2)] - module.y[int(module.y.shape[0] / 2):]\n",
    "\n",
    "    delta_in = module.x[: int(module.x.shape[0] / 2)] - module.x[int(module.x.shape[0] / 2):]\n",
    "    dup0 = [2] + [1 for i in delta_in.shape[1:]]\n",
    "    # handles numerical instabilities where delta_in is very small by\n",
    "    # just taking the gradient in those cases\n",
    "    grads = [None for _ in grad_input]\n",
    "    grads[0] = torch.where(torch.abs(delta_in.repeat(dup0)) < 1e-6, grad_input[0],\n",
    "                           grad_output[0] * (delta_out / delta_in).repeat(dup0))\n",
    "    return tuple(grads)\n",
    "\n",
    "\n",
    "op_handler = {}\n",
    "\n",
    "# passthrough ops, where we make no change to the gradient\n",
    "op_handler['Dropout3d'] = passthrough\n",
    "op_handler['Dropout2d'] = passthrough\n",
    "op_handler['Dropout'] = passthrough\n",
    "op_handler['AlphaDropout'] = passthrough\n",
    "\n",
    "op_handler['Conv1d'] = linear_1d\n",
    "op_handler['Conv2d'] = linear_1d\n",
    "op_handler['Conv3d'] = linear_1d\n",
    "op_handler['ConvTranspose1d'] = linear_1d\n",
    "op_handler['ConvTranspose2d'] = linear_1d\n",
    "op_handler['ConvTranspose3d'] = linear_1d\n",
    "op_handler['Linear'] = linear_1d\n",
    "op_handler['AvgPool1d'] = linear_1d\n",
    "op_handler['AvgPool2d'] = linear_1d\n",
    "op_handler['AvgPool3d'] = linear_1d\n",
    "op_handler['AdaptiveAvgPool1d'] = linear_1d\n",
    "op_handler['AdaptiveAvgPool2d'] = linear_1d\n",
    "op_handler['AdaptiveAvgPool3d'] = linear_1d\n",
    "op_handler['BatchNorm1d'] = linear_1d\n",
    "op_handler['BatchNorm2d'] = linear_1d\n",
    "op_handler['BatchNorm3d'] = linear_1d\n",
    "\n",
    "op_handler['LeakyReLU'] = nonlinear_1d\n",
    "op_handler['ReLU'] = nonlinear_1d\n",
    "op_handler['ELU'] = nonlinear_1d\n",
    "op_handler['Sigmoid'] = nonlinear_1d\n",
    "op_handler[\"Tanh\"] = nonlinear_1d\n",
    "op_handler[\"Softplus\"] = nonlinear_1d\n",
    "op_handler['Softmax'] = nonlinear_1d\n",
    "\n",
    "op_handler['MaxPool1d'] = maxpool\n",
    "op_handler['MaxPool2d'] = maxpool\n",
    "op_handler['MaxPool3d'] = maxpool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b783b97d-0567-47a1-9cfd-1912e618eecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1126719/2712065375.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  z = data.drop([\"patient_id\", \"OS\", \"OS.time\", \"age\", \"race_white\", \"stage_i\", \"stage_ii\", \"Prognosis_index\"], axis = 1).values.astype(np.float)\n",
      "/tmp/ipykernel_1126719/2712065375.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  age = data.loc[:, [\"age\"]].values.astype(np.float)\n",
      "/tmp/ipykernel_1126719/2712065375.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  stage_i = data.loc[:, [\"stage_i\"]].values.astype(np.float)\n",
      "/tmp/ipykernel_1126719/2712065375.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  stage_ii = data.loc[:, [\"stage_ii\"]].values.astype(np.float)\n",
      "/tmp/ipykernel_1126719/2712065375.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  race_white = data.loc[:, [\"race_white\"]].values.astype(np.float)\n",
      "/tmp/ipykernel_1126719/2712065375.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  z = data.drop([\"patient_id\", \"OS\", \"OS.time\", \"age\", \"race_white\", \"stage_i\", \"stage_ii\", \"Prognosis_index\"], axis = 1).values.astype(np.float)\n",
      "/tmp/ipykernel_1126719/2712065375.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  age = data.loc[:, [\"age\"]].values.astype(np.float)\n",
      "/tmp/ipykernel_1126719/2712065375.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  stage_i = data.loc[:, [\"stage_i\"]].values.astype(np.float)\n",
      "/tmp/ipykernel_1126719/2712065375.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  stage_ii = data.loc[:, [\"stage_ii\"]].values.astype(np.float)\n",
      "/tmp/ipykernel_1126719/2712065375.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  race_white = data.loc[:, [\"race_white\"]].values.astype(np.float)\n",
      "/common/sghoshstat/ywu39393/DKL/lib/python3.9/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating shap values\n",
      "calculated shap values\n",
      "   features  importance_vals\n",
      "10     Z_11         0.306294\n",
      "8       Z_9         0.227050\n",
      "9      Z_10         0.210699\n",
      "3       Z_4         0.108925\n",
      "6       Z_7         0.099804\n",
      "0       Z_1         0.093363\n",
      "7       Z_8         0.082649\n",
      "11     Z_12         0.044120\n",
      "5       Z_6         0.031249\n",
      "4       Z_5         0.021305\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "def getTopShapValues(shap_vals, numberOfTopFeatures, numberOfLatents, path, absolute=True):\n",
    "    multiple_input = False\n",
    "    if type(shap_vals) == list:\n",
    "        multiple_input = True\n",
    "        shap_values = None\n",
    "        for l in range(len(shap_vals)):\n",
    "            if shap_values is not None:\n",
    "                shap_values = np.concatenate((shap_values, shap_vals[l]), axis=1)\n",
    "            else:\n",
    "                shap_values = shap_vals[l]\n",
    "        shap_vals = shap_values\n",
    "    \n",
    "    if absolute:\n",
    "        vals = np.abs(shap_vals).mean(0)\n",
    "    else:\n",
    "        vals = shap_vals.mean(0)\n",
    "    \n",
    "    z_count = np.array(list(range(1, numberOfLatents+1, 1))).astype('str')\n",
    "    z_names = np.char.add('Z_', z_count).tolist()\n",
    "    \n",
    "    if multiple_input:\n",
    "        feature_names = z_names + ['age', 'stage_i', 'stage_ii', 'race_white']\n",
    "    else:\n",
    "        feature_names = z_names\n",
    "\n",
    "    feature_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                      columns=['features', 'importance_vals'])\n",
    "    feature_importance.sort_values(by=['importance_vals'], ascending=False, inplace=True)\n",
    "\n",
    "    mostImp_shap_values = feature_importance.head(numberOfTopFeatures)\n",
    "    print(mostImp_shap_values)\n",
    "\n",
    "    feature_importance.to_csv(path + \"/sup_feature_imp.csv\")\n",
    "    \"\"\"\n",
    "    print(mostImp_shap_values)\n",
    "    print(\"least importance absolute values\")\n",
    "    feature_importance.sort_values(by=['feature_importance_vals'], ascending=True, inplace=True)\n",
    "    leastImp_shap_values = feature_importance.head(numberOfTopFeatures)\n",
    "    print(leastImp_shap_values)\n",
    "    \"\"\"\n",
    "    return mostImp_shap_values\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def SupShapExplainer(train_overall_df, path, dimension):\n",
    "    #initialize LFSurv network with the set of optimal hyperparameters found via grid search during training/validation process\n",
    "    LFSurv_model = LFSurv(8, 32, 0.3, 0.1)\n",
    "    \n",
    "    #load trained model\n",
    "    LFSurv_model.load_state_dict(torch.load('saved_models/sup_checkpoint_overall.pt', map_location=torch.device('cpu')))\n",
    "    \n",
    "    condition1 = train_overall_df[\"Prognosis_index\"]>train_overall_df[\"Prognosis_index\"].median()\n",
    "    condition2 = train_overall_df[\"Prognosis_index\"]<=train_overall_df[\"Prognosis_index\"].median()\n",
    "    \n",
    "    #select certain data\n",
    "    upper_group_sample = splitExprandSample(condition=condition1, sampleSize=100, expr=train_overall_df)\n",
    "    lower_group_sample = splitExprandSample(condition=condition2, sampleSize=100, expr=train_overall_df)\n",
    "    \n",
    "    e = PyTorchDeepExplainer(LFSurv_model, lower_group_sample, outputNumber=0, dim=dimension, explainLatentSpace=False)\n",
    "    print(\"calculating shap values\")\n",
    "    shap_values_obtained = e.shap_values(upper_group_sample)\n",
    "    \n",
    "    print(\"calculated shap values\")\n",
    "    most_imp  = getTopShapValues(shap_vals=shap_values_obtained, numberOfTopFeatures=10, numberOfLatents=16, path=path, absolute=True)\n",
    "    \n",
    "    return most_imp\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "most_important_features = SupShapExplainer(train_overall_df=processed_tr, path='saved_models', dimension=0)\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cec2eda-8381-4e1f-a766-e49b6843d6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Z_11</td>\n",
       "      <td>0.306294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Z_9</td>\n",
       "      <td>0.227050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Z_10</td>\n",
       "      <td>0.210699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z_4</td>\n",
       "      <td>0.108925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Z_7</td>\n",
       "      <td>0.099804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z_1</td>\n",
       "      <td>0.093363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Z_8</td>\n",
       "      <td>0.082649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Z_12</td>\n",
       "      <td>0.044120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Z_6</td>\n",
       "      <td>0.031249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Z_5</td>\n",
       "      <td>0.021305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features  importance_vals\n",
       "10     Z_11         0.306294\n",
       "8       Z_9         0.227050\n",
       "9      Z_10         0.210699\n",
       "3       Z_4         0.108925\n",
       "6       Z_7         0.099804\n",
       "0       Z_1         0.093363\n",
       "7       Z_8         0.082649\n",
       "11     Z_12         0.044120\n",
       "5       Z_6         0.031249\n",
       "4       Z_5         0.021305"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_important_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DKL",
   "language": "python",
   "name": "dkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
