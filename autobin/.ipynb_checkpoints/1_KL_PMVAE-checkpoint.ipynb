{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6546b319-4813-4a08-b407-4775b18da49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from KL_PMVAE import KL_PMVAE_2omics, KL_PMVAE_genes, KL_PMVAE_mirnas\n",
    "from utils import sort_data, load_data, load_pathway, bce_recon_loss, kl_divergence, get_match_id\n",
    "from train_KL_PMVAE import train_KL_PMVAE\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e0b699-7d37-499d-8294-bce6e46fbb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/cloud-home/U1039935/Autosurv/autosurv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511be863-9ef0-4ae7-829e-b031203ea9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example listed here is for TCGA-BRCA data. If using TCGA-OV data, please adjust the parameters/covariates accordingly\n",
    "\"\"\"\n",
    "\n",
    "input_n1 = 2699\n",
    "input_n2 = 516\n",
    "z_dim = [8, 16, 32, 64]\n",
    "EPOCH_NUM = [800, 1200, 1600, 2000, 2400]\n",
    "NUM_CYCLES = [2, 4, 5, 10]\n",
    "Initial_Learning_Rate = [0.1, 0.05, 0.005, 0.001]\n",
    "L2_Lambda = [0.1, 0.05, 0.005, 0.0005]\n",
    "CUTTING_RATIO = [0.3, 0.5, 0.7, 0.9]\n",
    "# EPOCH_NUM = [800, 1200, 1600]\n",
    "# NUM_CYCLES = [2, 4]\n",
    "# Initial_Learning_Rate = [0.1, 0.01]\n",
    "# L2_Lambda = [0.1]\n",
    "patient_id_train, x_train_gene, ytime_train, yevent_train, age_train, stage_i_train, stage_ii_train, race_white_train = load_data(\"processed_data_example/TCGA_BRCA/tune/minmax_normalized/data_train_gene_minmax_tune.csv\", dtype)\n",
    "patient_id_valid, x_valid_gene, ytime_valid, yevent_valid, age_valid, stage_i_valid, stage_ii_valid, race_white_valid = load_data(\"processed_data_example/TCGA_BRCA/tune/minmax_normalized/data_valid_gene_minmax_tune.csv\", dtype)\n",
    "pathway_mask_tune = load_pathway(\"processed_data_example/TCGA_BRCA/tune/minmax_normalized/pathway_mask.csv\", dtype)\n",
    "\n",
    "_, x_train_mirna, _, _, _, _, _, _ = load_data(\"processed_data_example/TCGA_BRCA/tune/minmax_normalized/data_train_mirna_minmax_tune.csv\", dtype)\n",
    "_, x_valid_mirna, _, _, _, _, _, _ = load_data(\"processed_data_example/TCGA_BRCA/tune/minmax_normalized/data_valid_mirna_minmax_tune.csv\", dtype)\n",
    "\n",
    "\n",
    "\n",
    "patient_id_train_overall, x_train_gene_overall, ytime_train_overall, yevent_train_overall, age_train_overall, stage_i_train_overall, stage_ii_train_overall, race_white_train_overall = load_data(\"processed_data_example/TCGA_BRCA/train_test_split/minmax_normalized/data_train_gene_minmax_overall.csv\", dtype)\n",
    "patient_id_test_overall, x_test_gene_overall, ytime_test_overall, yevent_test_overall, age_test_overall, stage_i_test_overall, stage_ii_test_overall, race_white_test_overall = load_data(\"processed_data_example/TCGA_BRCA/train_test_split/minmax_normalized/data_test_gene_minmax_overall.csv\", dtype)\n",
    "pathway_mask_test = load_pathway(\"processed_data_example/TCGA_BRCA/train_test_split/minmax_normalized/pathway_mask.csv\", dtype)\n",
    "\n",
    "_, x_train_mirna_overall, _, _, _, _, _, _ = load_data(\"processed_data_example/TCGA_BRCA/train_test_split/minmax_normalized/data_train_mirna_minmax_overall.csv\", dtype)\n",
    "_, x_test_mirna_overall, _, _, _, _, _, _ = load_data(\"processed_data_example/TCGA_BRCA/train_test_split/minmax_normalized/data_test_mirna_minmax_overall.csv\", dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2351f-e935-47c8-83c5-b0f3533939ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abd72d2e-2372-44b1-8067-3cd558f40353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([669, 516])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mirna.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "831ae397-dfc8-4f0d-87e0-799c038fb33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([669, 2699])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_gene.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23131c50-44ba-4a20-aa1f-0b0214c5d7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([857, 2699])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_gene_overall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a722c525-ad0e-4c8e-afa9-22eac1888439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([201, 2699])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_gene_overall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05ef8f98-baf7-4fcb-b54e-6e9e220cb621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([581, 2699])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathway_mask_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ad123c8-3cf4-4ced-b1ea-95d368751ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"processed_data_example/TCGA_BRCA/tune/minmax_normalized/pathway_mask.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a98a1b85-152f-48ca-bcca-7e34bd0b3597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>R-HSA-1989781</th>\n",
       "      <th>R-HSA-418594</th>\n",
       "      <th>R-HSA-975298</th>\n",
       "      <th>R-HSA-418555</th>\n",
       "      <th>R-HSA-1442490</th>\n",
       "      <th>R-HSA-2565942</th>\n",
       "      <th>R-HSA-380259</th>\n",
       "      <th>R-HSA-380270</th>\n",
       "      <th>R-HSA-438066</th>\n",
       "      <th>...</th>\n",
       "      <th>R-HSA-373752</th>\n",
       "      <th>R-HSA-3000480</th>\n",
       "      <th>R-HSA-196299</th>\n",
       "      <th>R-HSA-3322077</th>\n",
       "      <th>R-HSA-1251985</th>\n",
       "      <th>R-HSA-5339716</th>\n",
       "      <th>R-HSA-5358747</th>\n",
       "      <th>R-HSA-5358749</th>\n",
       "      <th>R-HSA-5358751</th>\n",
       "      <th>R-HSA-5358752</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000001461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000001630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000003989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 582 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  R-HSA-1989781  R-HSA-418594  R-HSA-975298  R-HSA-418555  \\\n",
       "0  ENSG00000000938              0             0             0             0   \n",
       "1  ENSG00000000971              0             0             0             0   \n",
       "2  ENSG00000001461              0             0             0             0   \n",
       "3  ENSG00000001630              0             0             0             0   \n",
       "4  ENSG00000003989              0             0             0             0   \n",
       "\n",
       "   R-HSA-1442490  R-HSA-2565942  R-HSA-380259  R-HSA-380270  R-HSA-438066  \\\n",
       "0              0              0             0             0             0   \n",
       "1              0              0             0             0             0   \n",
       "2              0              0             0             0             0   \n",
       "3              0              0             0             0             0   \n",
       "4              0              0             0             0             0   \n",
       "\n",
       "   ...  R-HSA-373752  R-HSA-3000480  R-HSA-196299  R-HSA-3322077  \\\n",
       "0  ...             0              0             0              0   \n",
       "1  ...             0              0             0              0   \n",
       "2  ...             0              0             0              0   \n",
       "3  ...             0              0             0              0   \n",
       "4  ...             0              0             0              0   \n",
       "\n",
       "   R-HSA-1251985  R-HSA-5339716  R-HSA-5358747  R-HSA-5358749  R-HSA-5358751  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   R-HSA-5358752  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 582 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c379e6ea-c199-4006-bc81-a298382fae1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
      "\n",
      "[2699 rows x 0 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"processed_data_example/TCGA_BRCA/tune/minmax_normalized/pathway_mask.csv\")\n",
    "selected_columns = df.filter(like='1251999', axis=1)\n",
    "\n",
    "\n",
    "print(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8157b36a-bedd-4e75-a684-2350bdcc48e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathway_mask_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86a03e96-5864-456e-86de-798ecd16a29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48., 87.,  3., 53., 37., 36., 25., 28.,  5.,  3.,  5.,  7., 35., 43.,\n",
       "        45., 25., 10., 15.,  6., 19.,  5., 14., 10., 10.,  1., 14., 13.,  8.,\n",
       "        12.,  8.,  9., 16., 18., 13.,  6., 20., 16., 41., 19., 13., 38., 14.,\n",
       "        23., 34., 13.,  9., 16., 22., 16., 20., 16., 37., 35.,  8.,  5., 50.,\n",
       "        67., 18., 24., 16.,  5.,  8.,  6.,  6.,  6.,  5.,  6., 11., 14., 37.,\n",
       "         7.,  7.,  8.,  6., 30., 26., 29.,  8., 31., 58., 10., 15., 16., 14.,\n",
       "        11., 18., 17., 31., 35., 52.,  3., 12., 33., 66., 15., 27.,  8., 41.,\n",
       "        19., 33., 10.,  9.,  5.,  3., 12.,  7., 14.,  5.,  7., 12., 31.,  7.,\n",
       "         7., 35.,  8., 10., 10., 16., 23., 31., 13., 32., 14., 44., 22., 13.,\n",
       "         9., 14., 10., 18.,  8., 16., 36.,  5.,  6., 17.,  8., 44.,  8., 14.,\n",
       "        14., 14.,  9., 10., 27., 14.,  7.,  6.,  8.,  2., 21.,  8.,  7., 11.,\n",
       "        10.,  6., 23., 14.,  8., 11., 14., 14.,  7., 13.,  8., 43., 19.,  8.,\n",
       "        12., 12., 35.,  7., 42., 15., 11., 37.,  6., 11.,  9., 13.,  8.,  8.,\n",
       "         9., 12.,  9., 11.,  9.,  8., 14., 14., 14., 11.,  6.,  4.,  6., 11.,\n",
       "         6.,  6., 14.,  9., 18.,  8., 10.,  5., 14., 14., 14., 12., 14.,  8.,\n",
       "         7., 19.,  9., 58., 63., 37.,  3.,  6.,  9., 22.,  9., 10.,  9., 15.,\n",
       "        14., 31., 25., 29., 18., 29., 21., 17., 11., 13.,  6., 19.,  8.,  6.,\n",
       "         9.,  7., 10.,  5.,  4.,  4.,  6.,  8., 36., 18., 11., 15., 12., 41.,\n",
       "        27., 19., 10.,  8.,  8., 14., 15., 18., 11., 20., 29.,  6.,  4.,  6.,\n",
       "        30.,  9., 23., 25., 12., 10., 10., 23., 11.,  9.,  7., 11., 12., 13.,\n",
       "        10., 10., 22., 11.,  9., 13.,  9.,  8.,  9.,  8.,  8., 11., 13., 17.,\n",
       "        16.,  7., 10.,  8.,  8., 76., 44., 10., 36., 13., 15., 52., 12., 23.,\n",
       "        14., 25., 14., 27.,  7., 10., 12.,  9.,  7.,  6., 56., 31., 20., 14.,\n",
       "        16.,  9., 66., 70., 60.,  8., 10.,  9.,  9.,  9.,  9., 13.,  6.,  8.,\n",
       "        31., 13.,  5.,  4.,  7., 12., 10., 14., 14., 14., 16.,  6.,  1.,  3.,\n",
       "         9.,  7., 23.,  8., 26., 12.,  9.,  6.,  9., 29., 33., 17., 30., 15.,\n",
       "        17., 33.,  8., 14.,  5.,  4.,  5.,  6.,  4.,  7.,  4.,  8.,  5.,  5.,\n",
       "         8.,  5.,  4.,  4.,  7.,  5.,  5.,  8.,  8., 21.,  4., 14., 11.,  6.,\n",
       "         3.,  6.,  6., 38.,  6., 25., 12., 11., 38., 33., 14.,  5., 28., 29.,\n",
       "        26., 38., 32., 23., 29.,  4., 17., 17., 10.,  8., 15., 13., 10.,  4.,\n",
       "         4.,  7.,  6.,  7., 19., 39.,  8., 10.,  3., 11.,  6., 19.,  6., 18.,\n",
       "        20., 24., 25.,  9., 17.,  5.,  9., 12.,  6.,  9., 20.,  6., 16., 13.,\n",
       "        15., 14., 20., 11.,  5., 20.,  8.,  9.,  8., 13.,  5., 14.,  8.,  8.,\n",
       "        10.,  8.,  9.,  6.,  7.,  9.,  7., 14., 10., 12., 11., 19.,  7.,  7.,\n",
       "         8.,  8.,  8., 11., 11.,  9.,  9., 11.,  9.,  4.,  6.,  8.,  4.,  5.,\n",
       "        10.,  6., 13., 18.,  8.,  5., 26., 29., 27., 30.,  5., 17., 10., 18.,\n",
       "         5.,  8.,  8., 10.,  4., 15.,  8.,  7.,  5.,  9., 14., 13., 13.,  8.,\n",
       "        14.,  5., 10., 10., 17., 13., 11., 12., 10.,  3.,  3.,  7.,  2.,  3.,\n",
       "        16., 11.,  9.,  4.,  9., 18., 17.,  8., 12.,  9., 10., 11.,  8.,  6.,\n",
       "         7., 13.,  8.,  4.,  4.,  4.,  3.,  4., 10.,  6., 12.,  4.,  2., 19.,\n",
       "        12., 11.,  5., 13.,  3.,  8.,  3., 12.,  7.,  3.,  6., 11.,  7.,  6.,\n",
       "         3., 14.,  5.,  5.,  5.,  5.,  5.], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathway_mask_test.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88ad38f2-8e99-42ea-a2b2-195e4bf31664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([669, 2699])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_gene.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28480d93-ee61-4ef8-b4c5-084e401e6229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([857, 2699])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_gene_overall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7481bdfb-8690-48e5-b3f1-6bf56944652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([581, 2699]) torch.Size([581, 2699])\n"
     ]
    }
   ],
   "source": [
    "print(pathway_mask_tune.shape, pathway_mask_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92dc530-2b86-45e8-bc05-07bca648ffe4",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d423e-6a85-4088-833e-7a02bf1aa3d4",
   "metadata": {},
   "source": [
    "They first use tuned data(80% of the whole data) to find the optim parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfffe401-9b6d-4637-bc8e-e0dd4db879d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ca572-d9e2-49be-adc5-8a5a6ab2e41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cloud-home/U1039935/Autosurv/autosurv/KL_PMVAE.py:58: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  z = Variable(torch.cuda.FloatTensor(std.size()).normal_(0, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss in training: [1957.5905], loss in validation: [1984.7299].\n",
      "Epoch: 200, Loss in training: [1948.655], loss in validation: [1973.9113].\n",
      "Epoch: 300, Loss in training: [1948.4517], loss in validation: [1973.9257].\n",
      "Epoch: 400, Loss in training: [1944.0978], loss in validation: [1967.7988].\n",
      "Epoch: 500, Loss in training: [1952.493], loss in validation: [1978.1804].\n",
      "Epoch: 600, Loss in training: [1956.4406], loss in validation: [1981.2092].\n",
      "Epoch: 700, Loss in training: [1946.442], loss in validation: [1971.6672].\n",
      "Epoch: 800, Loss in training: [1951.0304], loss in validation: [1976.7177].\n",
      "3.94\n",
      "num_epoch: 800, num_cycles: 2, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1976.7177], loss in training: [1951.0304].\n",
      "Epoch: 100, Loss in training: [1949.2272], loss in validation: [1975.3872].\n",
      "Epoch: 200, Loss in training: [1947.4377], loss in validation: [1972.735].\n",
      "Epoch: 300, Loss in training: [1945.3647], loss in validation: [1969.0156].\n",
      "Epoch: 400, Loss in training: [1948.19], loss in validation: [1972.5814].\n",
      "Epoch: 500, Loss in training: [1944.2576], loss in validation: [1970.5314].\n",
      "Epoch: 600, Loss in training: [1951.5278], loss in validation: [1974.9888].\n",
      "Epoch: 700, Loss in training: [1979.313], loss in validation: [2004.923].\n",
      "Epoch: 800, Loss in training: [1945.4395], loss in validation: [1969.5126].\n",
      "2.92\n",
      "num_epoch: 800, num_cycles: 2, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1969.5126], loss in training: [1945.4395].\n",
      "Epoch: 100, Loss in training: [1955.2961], loss in validation: [1980.2906].\n",
      "Epoch: 200, Loss in training: [1955.4998], loss in validation: [1979.9174].\n",
      "Epoch: 300, Loss in training: [1947.8813], loss in validation: [1972.55].\n",
      "Epoch: 400, Loss in training: [1949.4048], loss in validation: [1975.0396].\n",
      "Epoch: 500, Loss in training: [1947.9174], loss in validation: [1973.0126].\n",
      "Epoch: 600, Loss in training: [1946.5085], loss in validation: [1969.139].\n",
      "Epoch: 700, Loss in training: [1944.5554], loss in validation: [1969.8698].\n",
      "Epoch: 800, Loss in training: [1944.504], loss in validation: [1969.05].\n",
      "2.88\n",
      "num_epoch: 800, num_cycles: 2, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1969.05], loss in training: [1944.504].\n",
      "Epoch: 100, Loss in training: [1947.8477], loss in validation: [1972.4843].\n",
      "Epoch: 200, Loss in training: [1953.0314], loss in validation: [1979.2614].\n",
      "Epoch: 300, Loss in training: [1944.8038], loss in validation: [1968.7572].\n",
      "Epoch: 400, Loss in training: [1953.9938], loss in validation: [1980.5516].\n",
      "Epoch: 500, Loss in training: [1956.1392], loss in validation: [1983.7178].\n",
      "Epoch: 600, Loss in training: [1946.1818], loss in validation: [1970.371].\n",
      "Epoch: 700, Loss in training: [1948.438], loss in validation: [1972.1].\n",
      "Epoch: 800, Loss in training: [1948.2714], loss in validation: [1972.3594].\n",
      "2.89\n",
      "num_epoch: 800, num_cycles: 2, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1972.3594], loss in training: [1948.2714].\n",
      "Epoch: 100, Loss in training: [1946.1478], loss in validation: [1970.789].\n",
      "Epoch: 200, Loss in training: [1953.2468], loss in validation: [1979.5878].\n",
      "Epoch: 300, Loss in training: [1948.5804], loss in validation: [1971.942].\n",
      "Epoch: 400, Loss in training: [1947.3302], loss in validation: [1973.1748].\n",
      "Epoch: 500, Loss in training: [1956.3038], loss in validation: [1979.0364].\n",
      "Epoch: 600, Loss in training: [1956.972], loss in validation: [1983.2002].\n",
      "Epoch: 700, Loss in training: [1945.0201], loss in validation: [1969.085].\n",
      "Epoch: 800, Loss in training: [1957.6667], loss in validation: [1983.717].\n",
      "2.91\n",
      "num_epoch: 800, num_cycles: 4, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1983.717], loss in training: [1957.6667].\n",
      "Epoch: 100, Loss in training: [1970.9852], loss in validation: [1999.6486].\n",
      "Epoch: 200, Loss in training: [1952.514], loss in validation: [1975.1558].\n",
      "Epoch: 300, Loss in training: [1948.58], loss in validation: [1973.849].\n",
      "Epoch: 400, Loss in training: [1953.5344], loss in validation: [1977.8754].\n",
      "Epoch: 500, Loss in training: [1952.52], loss in validation: [1976.404].\n",
      "Epoch: 600, Loss in training: [1947.8174], loss in validation: [1971.2114].\n",
      "Epoch: 700, Loss in training: [1945.1176], loss in validation: [1967.8574].\n",
      "Epoch: 800, Loss in training: [1954.7084], loss in validation: [1978.5554].\n",
      "2.95\n",
      "num_epoch: 800, num_cycles: 4, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1978.5554], loss in training: [1954.7084].\n",
      "Epoch: 100, Loss in training: [1963.9893], loss in validation: [1990.6736].\n",
      "Epoch: 200, Loss in training: [1947.5632], loss in validation: [1972.1827].\n",
      "Epoch: 300, Loss in training: [1947.0232], loss in validation: [1971.9294].\n",
      "Epoch: 400, Loss in training: [1947.7932], loss in validation: [1972.2657].\n",
      "Epoch: 500, Loss in training: [1963.7292], loss in validation: [1992.2021].\n",
      "Epoch: 600, Loss in training: [1946.1824], loss in validation: [1970.0958].\n",
      "Epoch: 700, Loss in training: [1946.8152], loss in validation: [1972.398].\n",
      "Epoch: 800, Loss in training: [1944.6718], loss in validation: [1968.5602].\n",
      "2.84\n",
      "num_epoch: 800, num_cycles: 4, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1968.5602], loss in training: [1944.6718].\n",
      "Epoch: 100, Loss in training: [1952.5682], loss in validation: [1978.0704].\n",
      "Epoch: 200, Loss in training: [1944.2156], loss in validation: [1968.6844].\n",
      "Epoch: 300, Loss in training: [1998.355], loss in validation: [2028.6158].\n",
      "Epoch: 400, Loss in training: [1942.9045], loss in validation: [1967.7087].\n",
      "Epoch: 500, Loss in training: [1950.8124], loss in validation: [1974.9897].\n",
      "Epoch: 600, Loss in training: [1957.5792], loss in validation: [1981.104].\n",
      "Epoch: 700, Loss in training: [1952.107], loss in validation: [1979.3962].\n",
      "Epoch: 800, Loss in training: [1954.2264], loss in validation: [1980.0348].\n",
      "2.94\n",
      "num_epoch: 800, num_cycles: 4, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1980.0348], loss in training: [1954.2264].\n",
      "Epoch: 100, Loss in training: [1959.4818], loss in validation: [1986.2532].\n",
      "Epoch: 200, Loss in training: [1948.733], loss in validation: [1972.0222].\n",
      "Epoch: 300, Loss in training: [1954.7936], loss in validation: [1979.0594].\n",
      "Epoch: 400, Loss in training: [1957.7548], loss in validation: [1984.2404].\n",
      "Epoch: 500, Loss in training: [1947.4272], loss in validation: [1971.983].\n",
      "Epoch: 600, Loss in training: [1954.0964], loss in validation: [1978.8672].\n",
      "Epoch: 700, Loss in training: [1947.3306], loss in validation: [1972.5952].\n",
      "Epoch: 800, Loss in training: [1943.7146], loss in validation: [1968.4294].\n",
      "2.95\n",
      "num_epoch: 800, num_cycles: 5, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1968.4294], loss in training: [1943.7146].\n",
      "Epoch: 100, Loss in training: [1957.0568], loss in validation: [1984.0942].\n",
      "Epoch: 200, Loss in training: [1960.5444], loss in validation: [1988.9252].\n",
      "Epoch: 300, Loss in training: [1947.965], loss in validation: [1973.3456].\n",
      "Epoch: 400, Loss in training: [1954.9868], loss in validation: [1982.887].\n",
      "Epoch: 500, Loss in training: [1951.542], loss in validation: [1977.3282].\n",
      "Epoch: 600, Loss in training: [1944.569], loss in validation: [1969.9858].\n",
      "Epoch: 700, Loss in training: [1955.044], loss in validation: [1983.1093].\n",
      "Epoch: 800, Loss in training: [1951.3276], loss in validation: [1975.0413].\n",
      "2.9\n",
      "num_epoch: 800, num_cycles: 5, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1975.0413], loss in training: [1951.3276].\n",
      "Epoch: 100, Loss in training: [1968.4396], loss in validation: [1996.7592].\n",
      "Epoch: 200, Loss in training: [1958.9843], loss in validation: [1985.553].\n",
      "Epoch: 300, Loss in training: [1958.2378], loss in validation: [1982.6895].\n",
      "Epoch: 400, Loss in training: [1947.3315], loss in validation: [1973.4246].\n",
      "Epoch: 500, Loss in training: [1948.435], loss in validation: [1971.4692].\n",
      "Epoch: 600, Loss in training: [1946.9434], loss in validation: [1970.5002].\n",
      "Epoch: 700, Loss in training: [1958.9672], loss in validation: [1982.8052].\n",
      "Epoch: 800, Loss in training: [1947.2656], loss in validation: [1971.3304].\n",
      "2.9\n",
      "num_epoch: 800, num_cycles: 5, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1971.3304], loss in training: [1947.2656].\n",
      "Epoch: 100, Loss in training: [1957.2222], loss in validation: [1982.9574].\n",
      "Epoch: 200, Loss in training: [1946.8315], loss in validation: [1971.4198].\n",
      "Epoch: 300, Loss in training: [1947.434], loss in validation: [1972.4906].\n",
      "Epoch: 400, Loss in training: [1946.2802], loss in validation: [1971.7144].\n",
      "Epoch: 500, Loss in training: [1931.999], loss in validation: [1955.5206].\n",
      "Epoch: 600, Loss in training: [1949.863], loss in validation: [1975.8].\n",
      "Epoch: 700, Loss in training: [1939.2769], loss in validation: [1964.6971].\n",
      "Epoch: 800, Loss in training: [1946.952], loss in validation: [1971.9128].\n",
      "3.1\n",
      "num_epoch: 800, num_cycles: 5, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1971.9128], loss in training: [1946.952].\n",
      "Epoch: 100, Loss in training: [1952.4897], loss in validation: [1977.8123].\n",
      "Epoch: 200, Loss in training: [1951.0922], loss in validation: [1975.8284].\n",
      "Epoch: 300, Loss in training: [1952.3994], loss in validation: [1977.0417].\n",
      "Epoch: 400, Loss in training: [1946.0146], loss in validation: [1970.163].\n",
      "Epoch: 500, Loss in training: [1947.2404], loss in validation: [1972.8036].\n",
      "Epoch: 600, Loss in training: [1949.5254], loss in validation: [1974.8668].\n",
      "Epoch: 700, Loss in training: [1947.0476], loss in validation: [1970.9688].\n",
      "Epoch: 800, Loss in training: [1946.2437], loss in validation: [1971.4926].\n",
      "2.96\n",
      "num_epoch: 800, num_cycles: 10, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1971.4926], loss in training: [1946.2437].\n",
      "Epoch: 100, Loss in training: [1944.3348], loss in validation: [1968.1984].\n",
      "Epoch: 200, Loss in training: [1962.7858], loss in validation: [1986.0695].\n",
      "Epoch: 300, Loss in training: [1951.827], loss in validation: [1978.0204].\n",
      "Epoch: 400, Loss in training: [1946.5164], loss in validation: [1972.6088].\n",
      "Epoch: 500, Loss in training: [1953.4897], loss in validation: [1976.3738].\n",
      "Epoch: 600, Loss in training: [1963.1102], loss in validation: [1990.5367].\n",
      "Epoch: 700, Loss in training: [1943.2534], loss in validation: [1966.7882].\n",
      "Epoch: 800, Loss in training: [1944.143], loss in validation: [1967.8812].\n",
      "2.86\n",
      "num_epoch: 800, num_cycles: 10, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1967.8812], loss in training: [1944.143].\n",
      "Epoch: 100, Loss in training: [1949.919], loss in validation: [1974.9062].\n",
      "Epoch: 200, Loss in training: [1950.893], loss in validation: [1976.0092].\n",
      "Epoch: 300, Loss in training: [1957.5084], loss in validation: [1982.8328].\n",
      "Epoch: 400, Loss in training: [1949.2513], loss in validation: [1971.634].\n",
      "Epoch: 500, Loss in training: [1947.107], loss in validation: [1970.564].\n",
      "Epoch: 600, Loss in training: [1954.178], loss in validation: [1981.1768].\n",
      "Epoch: 700, Loss in training: [1953.7694], loss in validation: [1979.3737].\n",
      "Epoch: 800, Loss in training: [1952.618], loss in validation: [1978.7146].\n",
      "2.93\n",
      "num_epoch: 800, num_cycles: 10, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1978.7146], loss in training: [1952.618].\n",
      "Epoch: 100, Loss in training: [1940.5594], loss in validation: [1964.7513].\n",
      "Epoch: 200, Loss in training: [1945.198], loss in validation: [1969.2563].\n",
      "Epoch: 300, Loss in training: [1952.044], loss in validation: [1977.132].\n",
      "Epoch: 400, Loss in training: [1946.6462], loss in validation: [1970.2155].\n",
      "Epoch: 500, Loss in training: [1941.9924], loss in validation: [1966.0148].\n",
      "Epoch: 600, Loss in training: [1947.1866], loss in validation: [1973.5].\n",
      "Epoch: 700, Loss in training: [1948.6014], loss in validation: [1973.05].\n",
      "Epoch: 800, Loss in training: [1953.3718], loss in validation: [1978.608].\n",
      "2.91\n",
      "num_epoch: 800, num_cycles: 10, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1978.608], loss in training: [1953.3718].\n",
      "Epoch: 100, Loss in training: [1962.0864], loss in validation: [1991.3267].\n",
      "Epoch: 200, Loss in training: [1948.4305], loss in validation: [1971.8088].\n",
      "Epoch: 300, Loss in training: [1962.4517], loss in validation: [1987.535].\n",
      "Epoch: 400, Loss in training: [1945.721], loss in validation: [1968.9702].\n",
      "Epoch: 500, Loss in training: [1952.8258], loss in validation: [1979.8654].\n",
      "Epoch: 600, Loss in training: [1975.4362], loss in validation: [2002.514].\n",
      "Epoch: 700, Loss in training: [1945.6946], loss in validation: [1970.3324].\n",
      "Epoch: 800, Loss in training: [1949.8992], loss in validation: [1976.9254].\n",
      "Epoch: 900, Loss in training: [1951.9852], loss in validation: [1976.1724].\n",
      "Epoch: 1000, Loss in training: [1949.1938], loss in validation: [1974.275].\n",
      "Epoch: 1100, Loss in training: [1946.602], loss in validation: [1971.5188].\n",
      "Epoch: 1200, Loss in training: [1947.624], loss in validation: [1972.8862].\n",
      "4.31\n",
      "num_epoch: 1200, num_cycles: 2, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1972.8862], loss in training: [1947.624].\n",
      "Epoch: 100, Loss in training: [1965.379], loss in validation: [1993.9368].\n",
      "Epoch: 200, Loss in training: [1967.6808], loss in validation: [1996.6166].\n",
      "Epoch: 300, Loss in training: [1943.8564], loss in validation: [1968.4148].\n",
      "Epoch: 400, Loss in training: [1946.1694], loss in validation: [1969.2478].\n",
      "Epoch: 500, Loss in training: [1953.246], loss in validation: [1978.8016].\n",
      "Epoch: 600, Loss in training: [1957.6548], loss in validation: [1982.977].\n",
      "Epoch: 700, Loss in training: [2006.3932], loss in validation: [2035.063].\n",
      "Epoch: 800, Loss in training: [1947.2338], loss in validation: [1969.9656].\n",
      "Epoch: 900, Loss in training: [1955.8145], loss in validation: [1980.6136].\n",
      "Epoch: 1000, Loss in training: [1959.0206], loss in validation: [1982.3964].\n",
      "Epoch: 1100, Loss in training: [1949.0789], loss in validation: [1973.51].\n",
      "Epoch: 1200, Loss in training: [1950.0522], loss in validation: [1974.648].\n",
      "4.37\n",
      "num_epoch: 1200, num_cycles: 2, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1974.648], loss in training: [1950.0522].\n",
      "Epoch: 100, Loss in training: [1952.411], loss in validation: [1979.1008].\n",
      "Epoch: 200, Loss in training: [1947.8636], loss in validation: [1973.106].\n",
      "Epoch: 300, Loss in training: [1954.6848], loss in validation: [1978.6364].\n",
      "Epoch: 400, Loss in training: [1945.993], loss in validation: [1970.8154].\n",
      "Epoch: 500, Loss in training: [1951.498], loss in validation: [1976.636].\n",
      "Epoch: 600, Loss in training: [1949.613], loss in validation: [1974.3372].\n",
      "Epoch: 700, Loss in training: [1947.3884], loss in validation: [1970.7253].\n",
      "Epoch: 800, Loss in training: [1961.6136], loss in validation: [1989.7412].\n",
      "Epoch: 900, Loss in training: [1949.8674], loss in validation: [1978.082].\n",
      "Epoch: 1000, Loss in training: [1948.5594], loss in validation: [1972.6403].\n",
      "Epoch: 1100, Loss in training: [1950.2585], loss in validation: [1974.7653].\n",
      "Epoch: 1200, Loss in training: [1959.5479], loss in validation: [1986.6598].\n",
      "4.32\n",
      "num_epoch: 1200, num_cycles: 2, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1986.6598], loss in training: [1959.5479].\n",
      "Epoch: 100, Loss in training: [1950.998], loss in validation: [1979.2062].\n",
      "Epoch: 200, Loss in training: [1943.9316], loss in validation: [1969.5308].\n",
      "Epoch: 300, Loss in training: [1945.5107], loss in validation: [1970.054].\n",
      "Epoch: 400, Loss in training: [1951.2823], loss in validation: [1974.288].\n",
      "Epoch: 500, Loss in training: [1993.081], loss in validation: [2018.7666].\n",
      "Epoch: 600, Loss in training: [1950.5804], loss in validation: [1974.423].\n",
      "Epoch: 700, Loss in training: [1949.9154], loss in validation: [1976.009].\n",
      "Epoch: 800, Loss in training: [1977.0212], loss in validation: [1999.9706].\n",
      "Epoch: 900, Loss in training: [1946.8134], loss in validation: [1971.995].\n",
      "Epoch: 1000, Loss in training: [1952.219], loss in validation: [1976.7299].\n",
      "Epoch: 1100, Loss in training: [1950.9606], loss in validation: [1975.8062].\n",
      "Epoch: 1200, Loss in training: [1950.9414], loss in validation: [1974.6187].\n",
      "4.3\n",
      "num_epoch: 1200, num_cycles: 2, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1974.6187], loss in training: [1950.9414].\n",
      "Epoch: 100, Loss in training: [1961.9832], loss in validation: [1990.4642].\n",
      "Epoch: 200, Loss in training: [1951.1036], loss in validation: [1975.6586].\n",
      "Epoch: 300, Loss in training: [1947.1006], loss in validation: [1972.6075].\n",
      "Epoch: 400, Loss in training: [1949.6136], loss in validation: [1973.9521].\n",
      "Epoch: 500, Loss in training: [1943.8217], loss in validation: [1966.949].\n",
      "Epoch: 600, Loss in training: [1949.8882], loss in validation: [1973.5646].\n",
      "Epoch: 700, Loss in training: [1948.4543], loss in validation: [1973.0336].\n",
      "Epoch: 800, Loss in training: [1949.2559], loss in validation: [1974.5896].\n",
      "Epoch: 900, Loss in training: [1947.117], loss in validation: [1973.127].\n",
      "Epoch: 1000, Loss in training: [1951.4937], loss in validation: [1976.4272].\n",
      "Epoch: 1100, Loss in training: [1948.555], loss in validation: [1972.3018].\n",
      "Epoch: 1200, Loss in training: [1960.8396], loss in validation: [1985.5314].\n",
      "4.39\n",
      "num_epoch: 1200, num_cycles: 4, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1985.5314], loss in training: [1960.8396].\n",
      "Epoch: 100, Loss in training: [1959.0936], loss in validation: [1986.3224].\n",
      "Epoch: 200, Loss in training: [1946.1595], loss in validation: [1970.5968].\n",
      "Epoch: 300, Loss in training: [1954.2886], loss in validation: [1980.9106].\n",
      "Epoch: 400, Loss in training: [1950.5582], loss in validation: [1976.7039].\n",
      "Epoch: 500, Loss in training: [1948.6466], loss in validation: [1972.2128].\n",
      "Epoch: 600, Loss in training: [1947.8088], loss in validation: [1971.9722].\n",
      "Epoch: 700, Loss in training: [1967.8234], loss in validation: [1993.9178].\n",
      "Epoch: 800, Loss in training: [1952.1357], loss in validation: [1977.7238].\n",
      "Epoch: 900, Loss in training: [1967.7856], loss in validation: [1993.9].\n",
      "Epoch: 1000, Loss in training: [1950.014], loss in validation: [1973.7136].\n",
      "Epoch: 1100, Loss in training: [1948.2118], loss in validation: [1973.2672].\n",
      "Epoch: 1200, Loss in training: [1956.0771], loss in validation: [1980.4233].\n",
      "4.33\n",
      "num_epoch: 1200, num_cycles: 4, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1980.4233], loss in training: [1956.0771].\n",
      "Epoch: 100, Loss in training: [1963.544], loss in validation: [1991.388].\n",
      "Epoch: 200, Loss in training: [1950.8578], loss in validation: [1977.8221].\n",
      "Epoch: 300, Loss in training: [1958.082], loss in validation: [1983.626].\n",
      "Epoch: 400, Loss in training: [1944.1742], loss in validation: [1968.4257].\n",
      "Epoch: 500, Loss in training: [1948.5082], loss in validation: [1973.217].\n",
      "Epoch: 600, Loss in training: [1949.0162], loss in validation: [1972.6072].\n",
      "Epoch: 700, Loss in training: [1950.0984], loss in validation: [1975.6664].\n",
      "Epoch: 800, Loss in training: [1947.5912], loss in validation: [1971.09].\n",
      "Epoch: 900, Loss in training: [1959.623], loss in validation: [1985.0054].\n",
      "Epoch: 1000, Loss in training: [1956.3575], loss in validation: [1982.8552].\n",
      "Epoch: 1100, Loss in training: [1956.3806], loss in validation: [1979.4636].\n",
      "Epoch: 1200, Loss in training: [1950.644], loss in validation: [1974.1858].\n",
      "4.4\n",
      "num_epoch: 1200, num_cycles: 4, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1974.1858], loss in training: [1950.644].\n",
      "Epoch: 100, Loss in training: [1955.1466], loss in validation: [1980.2266].\n",
      "Epoch: 200, Loss in training: [1946.372], loss in validation: [1969.4392].\n",
      "Epoch: 300, Loss in training: [1952.6154], loss in validation: [1975.7214].\n",
      "Epoch: 400, Loss in training: [1969.8538], loss in validation: [1998.5573].\n",
      "Epoch: 500, Loss in training: [1949.257], loss in validation: [1972.6992].\n",
      "Epoch: 600, Loss in training: [1947.4714], loss in validation: [1970.5776].\n",
      "Epoch: 700, Loss in training: [1946.1626], loss in validation: [1970.5714].\n",
      "Epoch: 800, Loss in training: [1946.6942], loss in validation: [1970.8966].\n",
      "Epoch: 900, Loss in training: [1946.2186], loss in validation: [1971.3254].\n",
      "Epoch: 1000, Loss in training: [1949.6074], loss in validation: [1977.148].\n",
      "Epoch: 1100, Loss in training: [1943.5568], loss in validation: [1967.9158].\n",
      "Epoch: 1200, Loss in training: [1948.4427], loss in validation: [1973.5592].\n",
      "4.33\n",
      "num_epoch: 1200, num_cycles: 4, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1973.5592], loss in training: [1948.4427].\n",
      "Epoch: 100, Loss in training: [1958.1116], loss in validation: [1983.3668].\n",
      "Epoch: 200, Loss in training: [1946.5226], loss in validation: [1971.6104].\n",
      "Epoch: 300, Loss in training: [1954.2554], loss in validation: [1978.3608].\n",
      "Epoch: 400, Loss in training: [1952.8503], loss in validation: [1975.0994].\n",
      "Epoch: 500, Loss in training: [1963.3192], loss in validation: [1991.5106].\n",
      "Epoch: 600, Loss in training: [1945.5306], loss in validation: [1970.2332].\n",
      "Epoch: 700, Loss in training: [1945.7094], loss in validation: [1970.5126].\n",
      "Epoch: 800, Loss in training: [1960.2563], loss in validation: [1986.2858].\n",
      "Epoch: 900, Loss in training: [1947.3289], loss in validation: [1972.5366].\n",
      "Epoch: 1000, Loss in training: [2010.0273], loss in validation: [2044.486].\n",
      "Epoch: 1100, Loss in training: [1972.7916], loss in validation: [2000.295].\n",
      "Epoch: 1200, Loss in training: [1947.4517], loss in validation: [1972.3466].\n",
      "4.34\n",
      "num_epoch: 1200, num_cycles: 5, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1972.3466], loss in training: [1947.4517].\n",
      "Epoch: 100, Loss in training: [1953.9828], loss in validation: [1978.4712].\n",
      "Epoch: 200, Loss in training: [1945.4272], loss in validation: [1969.4764].\n",
      "Epoch: 300, Loss in training: [1960.4207], loss in validation: [1986.3456].\n",
      "Epoch: 400, Loss in training: [1943.9338], loss in validation: [1966.4677].\n",
      "Epoch: 500, Loss in training: [1942.3918], loss in validation: [1963.653].\n",
      "Epoch: 600, Loss in training: [1943.7708], loss in validation: [1966.9471].\n",
      "Epoch: 700, Loss in training: [1945.6914], loss in validation: [1969.6237].\n",
      "Epoch: 800, Loss in training: [1947.0938], loss in validation: [1971.6038].\n",
      "Epoch: 900, Loss in training: [1961.3195], loss in validation: [1984.638].\n",
      "Epoch: 1000, Loss in training: [1956.2966], loss in validation: [1980.08].\n",
      "Epoch: 1100, Loss in training: [1945.5702], loss in validation: [1970.0815].\n",
      "Epoch: 1200, Loss in training: [1945.657], loss in validation: [1971.1165].\n",
      "4.39\n",
      "num_epoch: 1200, num_cycles: 5, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1971.1165], loss in training: [1945.657].\n",
      "Epoch: 100, Loss in training: [1954.477], loss in validation: [1981.4412].\n",
      "Epoch: 200, Loss in training: [1949.7535], loss in validation: [1974.5432].\n",
      "Epoch: 300, Loss in training: [1954.1882], loss in validation: [1978.2522].\n",
      "Epoch: 400, Loss in training: [1948.2662], loss in validation: [1972.1584].\n",
      "Epoch: 500, Loss in training: [1951.3522], loss in validation: [1976.5284].\n",
      "Epoch: 600, Loss in training: [1945.4818], loss in validation: [1968.316].\n",
      "Epoch: 700, Loss in training: [1943.8784], loss in validation: [1968.101].\n",
      "Epoch: 800, Loss in training: [1948.4902], loss in validation: [1975.0604].\n",
      "Epoch: 900, Loss in training: [1952.7574], loss in validation: [1977.0142].\n",
      "Epoch: 1000, Loss in training: [1938.3948], loss in validation: [1962.5767].\n",
      "Epoch: 1100, Loss in training: [1947.81], loss in validation: [1972.0684].\n",
      "Epoch: 1200, Loss in training: [1950.9946], loss in validation: [1975.6971].\n",
      "4.44\n",
      "num_epoch: 1200, num_cycles: 5, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1975.6971], loss in training: [1950.9946].\n",
      "Epoch: 100, Loss in training: [1948.829], loss in validation: [1975.0782].\n",
      "Epoch: 200, Loss in training: [1944.6952], loss in validation: [1969.4705].\n",
      "Epoch: 300, Loss in training: [1949.7186], loss in validation: [1976.3948].\n",
      "Epoch: 400, Loss in training: [1949.9594], loss in validation: [1974.3796].\n",
      "Epoch: 500, Loss in training: [1938.3656], loss in validation: [1961.8914].\n",
      "Epoch: 600, Loss in training: [1951.663], loss in validation: [1976.8804].\n",
      "Epoch: 700, Loss in training: [1945.7324], loss in validation: [1971.5784].\n",
      "Epoch: 800, Loss in training: [1945.4896], loss in validation: [1970.3798].\n",
      "Epoch: 900, Loss in training: [1944.9044], loss in validation: [1970.6108].\n",
      "Epoch: 1000, Loss in training: [1949.176], loss in validation: [1974.1174].\n",
      "Epoch: 1100, Loss in training: [1955.31], loss in validation: [1979.4852].\n",
      "Epoch: 1200, Loss in training: [1943.5385], loss in validation: [1967.4001].\n",
      "4.52\n",
      "num_epoch: 1200, num_cycles: 5, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1967.4001], loss in training: [1943.5385].\n",
      "Epoch: 100, Loss in training: [1957.8142], loss in validation: [1984.5135].\n",
      "Epoch: 200, Loss in training: [1950.1053], loss in validation: [1973.2732].\n",
      "Epoch: 300, Loss in training: [1952.574], loss in validation: [1978.2234].\n",
      "Epoch: 400, Loss in training: [1949.519], loss in validation: [1975.072].\n",
      "Epoch: 500, Loss in training: [1942.9406], loss in validation: [1968.4026].\n",
      "Epoch: 600, Loss in training: [1969.0498], loss in validation: [1995.3643].\n",
      "Epoch: 700, Loss in training: [1950.5596], loss in validation: [1975.2692].\n",
      "Epoch: 800, Loss in training: [1950.0103], loss in validation: [1975.4727].\n",
      "Epoch: 900, Loss in training: [1952.9019], loss in validation: [1978.1584].\n",
      "Epoch: 1000, Loss in training: [1959.523], loss in validation: [1984.5378].\n",
      "Epoch: 1100, Loss in training: [2011.2156], loss in validation: [2039.6268].\n",
      "Epoch: 1200, Loss in training: [1949.929], loss in validation: [1975.1782].\n",
      "4.39\n",
      "num_epoch: 1200, num_cycles: 10, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1975.1782], loss in training: [1949.929].\n",
      "Epoch: 100, Loss in training: [1954.0344], loss in validation: [1978.9108].\n",
      "Epoch: 200, Loss in training: [1954.0966], loss in validation: [1978.7744].\n",
      "Epoch: 300, Loss in training: [1948.535], loss in validation: [1974.0776].\n",
      "Epoch: 400, Loss in training: [1946.6478], loss in validation: [1972.2844].\n",
      "Epoch: 500, Loss in training: [1947.274], loss in validation: [1970.5645].\n",
      "Epoch: 600, Loss in training: [1950.2032], loss in validation: [1974.6658].\n",
      "Epoch: 700, Loss in training: [1948.7708], loss in validation: [1974.1088].\n",
      "Epoch: 800, Loss in training: [1945.7682], loss in validation: [1970.3344].\n",
      "Epoch: 900, Loss in training: [1951.9758], loss in validation: [1977.0186].\n",
      "Epoch: 1000, Loss in training: [1953.9512], loss in validation: [1977.6324].\n",
      "Epoch: 1100, Loss in training: [1942.0444], loss in validation: [1965.999].\n",
      "Epoch: 1200, Loss in training: [1945.2302], loss in validation: [1968.223].\n",
      "4.38\n",
      "num_epoch: 1200, num_cycles: 10, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1968.223], loss in training: [1945.2302].\n",
      "Epoch: 100, Loss in training: [1957.7698], loss in validation: [1983.971].\n",
      "Epoch: 200, Loss in training: [1953.3712], loss in validation: [1978.7322].\n",
      "Epoch: 300, Loss in training: [1950.4764], loss in validation: [1975.5085].\n",
      "Epoch: 400, Loss in training: [1946.858], loss in validation: [1970.4386].\n",
      "Epoch: 500, Loss in training: [1944.7094], loss in validation: [1971.7137].\n",
      "Epoch: 600, Loss in training: [1948.0052], loss in validation: [1973.42].\n",
      "Epoch: 700, Loss in training: [1946.6375], loss in validation: [1972.4236].\n",
      "Epoch: 800, Loss in training: [1948.5624], loss in validation: [1974.444].\n",
      "Epoch: 900, Loss in training: [1952.1158], loss in validation: [1978.5876].\n",
      "Epoch: 1000, Loss in training: [1944.4633], loss in validation: [1968.5664].\n",
      "Epoch: 1100, Loss in training: [1958.6858], loss in validation: [1983.9279].\n",
      "Epoch: 1200, Loss in training: [1944.7758], loss in validation: [1970.56].\n",
      "4.39\n",
      "num_epoch: 1200, num_cycles: 10, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1970.56], loss in training: [1944.7758].\n",
      "Epoch: 100, Loss in training: [1958.4113], loss in validation: [1985.546].\n",
      "Epoch: 200, Loss in training: [1944.3975], loss in validation: [1968.899].\n",
      "Epoch: 300, Loss in training: [1951.6038], loss in validation: [1977.253].\n",
      "Epoch: 400, Loss in training: [1947.2798], loss in validation: [1972.2828].\n",
      "Epoch: 500, Loss in training: [1935.447], loss in validation: [1959.3876].\n",
      "Epoch: 600, Loss in training: [1950.5898], loss in validation: [1974.493].\n",
      "Epoch: 700, Loss in training: [1944.4832], loss in validation: [1967.8124].\n",
      "Epoch: 800, Loss in training: [1943.889], loss in validation: [1968.1158].\n",
      "Epoch: 900, Loss in training: [1960.679], loss in validation: [1986.5486].\n",
      "Epoch: 1000, Loss in training: [1952.1862], loss in validation: [1974.6896].\n",
      "Epoch: 1100, Loss in training: [1939.0286], loss in validation: [1961.5107].\n",
      "Epoch: 1200, Loss in training: [1946.5878], loss in validation: [1970.2428].\n",
      "4.37\n",
      "num_epoch: 1200, num_cycles: 10, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1970.2428], loss in training: [1946.5878].\n",
      "Epoch: 100, Loss in training: [1951.3715], loss in validation: [1978.7638].\n",
      "Epoch: 200, Loss in training: [1959.3674], loss in validation: [1986.1818].\n",
      "Epoch: 300, Loss in training: [1944.5822], loss in validation: [1967.8494].\n",
      "Epoch: 400, Loss in training: [1947.6908], loss in validation: [1973.4073].\n",
      "Epoch: 500, Loss in training: [1944.233], loss in validation: [1968.6779].\n",
      "Epoch: 600, Loss in training: [1947.5796], loss in validation: [1970.6805].\n",
      "Epoch: 700, Loss in training: [1951.5972], loss in validation: [1976.4728].\n",
      "Epoch: 800, Loss in training: [1945.5438], loss in validation: [1970.9462].\n",
      "Epoch: 900, Loss in training: [1945.2958], loss in validation: [1970.5804].\n",
      "Epoch: 1000, Loss in training: [1946.6147], loss in validation: [1970.4417].\n",
      "Epoch: 1100, Loss in training: [1946.6666], loss in validation: [1970.4888].\n",
      "Epoch: 1200, Loss in training: [1951.7336], loss in validation: [1976.6138].\n",
      "Epoch: 1300, Loss in training: [1952.4264], loss in validation: [1977.8108].\n",
      "Epoch: 1400, Loss in training: [1947.0602], loss in validation: [1971.5208].\n",
      "Epoch: 1500, Loss in training: [1948.372], loss in validation: [1972.544].\n",
      "Epoch: 1600, Loss in training: [1952.9218], loss in validation: [1976.6335].\n",
      "5.84\n",
      "num_epoch: 1600, num_cycles: 2, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1976.6335], loss in training: [1952.9218].\n",
      "Epoch: 100, Loss in training: [1955.527], loss in validation: [1981.6562].\n",
      "Epoch: 200, Loss in training: [1942.8732], loss in validation: [1966.8982].\n",
      "Epoch: 300, Loss in training: [1954.1174], loss in validation: [1979.341].\n",
      "Epoch: 400, Loss in training: [1948.7424], loss in validation: [1972.8289].\n",
      "Epoch: 500, Loss in training: [1947.9606], loss in validation: [1972.3882].\n",
      "Epoch: 600, Loss in training: [1945.5786], loss in validation: [1967.762].\n",
      "Epoch: 700, Loss in training: [1944.411], loss in validation: [1967.5364].\n",
      "Epoch: 800, Loss in training: [1946.817], loss in validation: [1969.946].\n",
      "Epoch: 900, Loss in training: [1940.2607], loss in validation: [1963.4467].\n",
      "Epoch: 1000, Loss in training: [1948.8136], loss in validation: [1972.507].\n",
      "Epoch: 1100, Loss in training: [1948.064], loss in validation: [1971.9348].\n",
      "Epoch: 1200, Loss in training: [1952.2916], loss in validation: [1975.434].\n",
      "Epoch: 1300, Loss in training: [1945.8062], loss in validation: [1969.0936].\n",
      "Epoch: 1400, Loss in training: [1947.24], loss in validation: [1972.0682].\n",
      "Epoch: 1500, Loss in training: [1950.4825], loss in validation: [1975.1938].\n",
      "Epoch: 1600, Loss in training: [1946.7722], loss in validation: [1971.1588].\n",
      "5.83\n",
      "num_epoch: 1600, num_cycles: 2, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1971.1588], loss in training: [1946.7722].\n",
      "Epoch: 100, Loss in training: [1957.5514], loss in validation: [1984.9222].\n",
      "Epoch: 200, Loss in training: [1949.7102], loss in validation: [1975.1403].\n",
      "Epoch: 300, Loss in training: [1941.3029], loss in validation: [1966.3885].\n",
      "Epoch: 400, Loss in training: [1946.9376], loss in validation: [1971.3167].\n",
      "Epoch: 500, Loss in training: [1959.1674], loss in validation: [1984.548].\n",
      "Epoch: 600, Loss in training: [1952.4836], loss in validation: [1976.2562].\n",
      "Epoch: 700, Loss in training: [1949.9476], loss in validation: [1973.7155].\n",
      "Epoch: 800, Loss in training: [1945.1884], loss in validation: [1969.4427].\n",
      "Epoch: 900, Loss in training: [1940.168], loss in validation: [1963.2826].\n",
      "Epoch: 1000, Loss in training: [1938.6962], loss in validation: [1962.898].\n",
      "Epoch: 1100, Loss in training: [1947.544], loss in validation: [1973.394].\n",
      "Epoch: 1200, Loss in training: [1944.2434], loss in validation: [1969.6038].\n",
      "Epoch: 1300, Loss in training: [1950.8268], loss in validation: [1974.9888].\n",
      "Epoch: 1400, Loss in training: [1943.1232], loss in validation: [1967.8038].\n",
      "Epoch: 1500, Loss in training: [1957.8676], loss in validation: [1980.3662].\n",
      "Epoch: 1600, Loss in training: [1944.2491], loss in validation: [1970.4135].\n",
      "5.84\n",
      "num_epoch: 1600, num_cycles: 2, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1970.4135], loss in training: [1944.2491].\n",
      "Epoch: 100, Loss in training: [1960.7552], loss in validation: [1989.576].\n",
      "Epoch: 200, Loss in training: [1961.53], loss in validation: [1987.5602].\n",
      "Epoch: 300, Loss in training: [1944.9432], loss in validation: [1968.6842].\n",
      "Epoch: 400, Loss in training: [1965.0247], loss in validation: [1993.7126].\n",
      "Epoch: 500, Loss in training: [1945.0408], loss in validation: [1969.5474].\n",
      "Epoch: 600, Loss in training: [1942.0876], loss in validation: [1966.3854].\n",
      "Epoch: 700, Loss in training: [1950.6272], loss in validation: [1976.2854].\n",
      "Epoch: 800, Loss in training: [1960.924], loss in validation: [1987.1396].\n",
      "Epoch: 900, Loss in training: [1949.8029], loss in validation: [1977.7438].\n",
      "Epoch: 1000, Loss in training: [1947.6766], loss in validation: [1971.9578].\n",
      "Epoch: 1100, Loss in training: [1944.4436], loss in validation: [1970.142].\n",
      "Epoch: 1200, Loss in training: [1946.5931], loss in validation: [1972.9476].\n",
      "Epoch: 1300, Loss in training: [1975.1956], loss in validation: [2001.001].\n",
      "Epoch: 1400, Loss in training: [1953.742], loss in validation: [1979.406].\n",
      "Epoch: 1500, Loss in training: [1952.0432], loss in validation: [1976.1232].\n",
      "Epoch: 1600, Loss in training: [1954.6862], loss in validation: [1980.3997].\n",
      "5.79\n",
      "num_epoch: 1600, num_cycles: 2, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1980.3997], loss in training: [1954.6862].\n",
      "Epoch: 100, Loss in training: [1952.5114], loss in validation: [1977.0024].\n",
      "Epoch: 200, Loss in training: [1950.1146], loss in validation: [1973.4966].\n",
      "Epoch: 300, Loss in training: [1954.6512], loss in validation: [1979.6786].\n",
      "Epoch: 400, Loss in training: [1951.4012], loss in validation: [1976.7347].\n",
      "Epoch: 500, Loss in training: [1950.2026], loss in validation: [1975.553].\n",
      "Epoch: 600, Loss in training: [1952.2347], loss in validation: [1976.196].\n",
      "Epoch: 700, Loss in training: [1950.5256], loss in validation: [1977.5742].\n",
      "Epoch: 800, Loss in training: [1954.2653], loss in validation: [1980.6086].\n",
      "Epoch: 900, Loss in training: [1950.569], loss in validation: [1975.7675].\n",
      "Epoch: 1000, Loss in training: [1947.6738], loss in validation: [1971.4628].\n",
      "Epoch: 1100, Loss in training: [1956.9098], loss in validation: [1984.0848].\n",
      "Epoch: 1200, Loss in training: [1945.7922], loss in validation: [1969.993].\n",
      "Epoch: 1300, Loss in training: [1963.8809], loss in validation: [1986.733].\n",
      "Epoch: 1400, Loss in training: [1949.4204], loss in validation: [1971.9534].\n",
      "Epoch: 1500, Loss in training: [1948.3286], loss in validation: [1973.107].\n",
      "Epoch: 1600, Loss in training: [1963.8944], loss in validation: [1986.8422].\n",
      "5.87\n",
      "num_epoch: 1600, num_cycles: 4, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1986.8422], loss in training: [1963.8944].\n",
      "Epoch: 100, Loss in training: [1954.6993], loss in validation: [1981.1318].\n",
      "Epoch: 200, Loss in training: [1943.9023], loss in validation: [1968.1602].\n",
      "Epoch: 300, Loss in training: [1951.9406], loss in validation: [1975.4158].\n",
      "Epoch: 400, Loss in training: [1955.6432], loss in validation: [1978.4412].\n",
      "Epoch: 500, Loss in training: [1954.6156], loss in validation: [1980.8242].\n",
      "Epoch: 600, Loss in training: [1955.2606], loss in validation: [1980.9587].\n",
      "Epoch: 700, Loss in training: [1952.627], loss in validation: [1978.6215].\n",
      "Epoch: 800, Loss in training: [1950.8464], loss in validation: [1976.7186].\n",
      "Epoch: 900, Loss in training: [1948.5048], loss in validation: [1975.7532].\n",
      "Epoch: 1000, Loss in training: [1953.279], loss in validation: [1979.8022].\n",
      "Epoch: 1100, Loss in training: [1952.7814], loss in validation: [1976.602].\n",
      "Epoch: 1200, Loss in training: [1952.0836], loss in validation: [1975.3503].\n",
      "Epoch: 1300, Loss in training: [1944.0002], loss in validation: [1967.7415].\n",
      "Epoch: 1400, Loss in training: [1961.3964], loss in validation: [1987.0262].\n",
      "Epoch: 1500, Loss in training: [1954.0435], loss in validation: [1979.6938].\n",
      "Epoch: 1600, Loss in training: [1948.398], loss in validation: [1973.4614].\n",
      "5.8\n",
      "num_epoch: 1600, num_cycles: 4, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1973.4614], loss in training: [1948.398].\n",
      "Epoch: 100, Loss in training: [1953.2274], loss in validation: [1979.2325].\n",
      "Epoch: 200, Loss in training: [1946.8882], loss in validation: [1972.0208].\n",
      "Epoch: 300, Loss in training: [1946.0264], loss in validation: [1970.7867].\n",
      "Epoch: 400, Loss in training: [1944.9796], loss in validation: [1969.8862].\n",
      "Epoch: 500, Loss in training: [1935.5232], loss in validation: [1958.7896].\n",
      "Epoch: 600, Loss in training: [1941.1958], loss in validation: [1965.8444].\n",
      "Epoch: 700, Loss in training: [1944.6823], loss in validation: [1969.234].\n",
      "Epoch: 800, Loss in training: [1948.6357], loss in validation: [1972.5955].\n",
      "Epoch: 900, Loss in training: [1943.35], loss in validation: [1967.2491].\n",
      "Epoch: 1000, Loss in training: [1949.6422], loss in validation: [1974.0502].\n",
      "Epoch: 1100, Loss in training: [1945.8958], loss in validation: [1971.5457].\n",
      "Epoch: 1200, Loss in training: [1950.966], loss in validation: [1976.9116].\n",
      "Epoch: 1300, Loss in training: [1950.4772], loss in validation: [1974.9766].\n",
      "Epoch: 1400, Loss in training: [1955.2043], loss in validation: [1980.2164].\n",
      "Epoch: 1500, Loss in training: [1952.6208], loss in validation: [1978.6292].\n",
      "Epoch: 1600, Loss in training: [1946.668], loss in validation: [1970.7961].\n",
      "6.03\n",
      "num_epoch: 1600, num_cycles: 4, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1970.7961], loss in training: [1946.668].\n",
      "Epoch: 100, Loss in training: [1943.8942], loss in validation: [1970.1254].\n",
      "Epoch: 200, Loss in training: [1952.6104], loss in validation: [1980.4502].\n",
      "Epoch: 300, Loss in training: [1945.1708], loss in validation: [1970.9167].\n",
      "Epoch: 400, Loss in training: [1951.2692], loss in validation: [1977.4749].\n",
      "Epoch: 500, Loss in training: [1945.492], loss in validation: [1970.6326].\n",
      "Epoch: 600, Loss in training: [1944.1982], loss in validation: [1969.5074].\n",
      "Epoch: 700, Loss in training: [1951.3098], loss in validation: [1977.4008].\n",
      "Epoch: 800, Loss in training: [1948.1407], loss in validation: [1972.3854].\n",
      "Epoch: 900, Loss in training: [1946.4556], loss in validation: [1970.575].\n",
      "Epoch: 1000, Loss in training: [1952.4614], loss in validation: [1975.7424].\n",
      "Epoch: 1100, Loss in training: [1951.5154], loss in validation: [1977.7646].\n",
      "Epoch: 1200, Loss in training: [1944.6786], loss in validation: [1968.9534].\n",
      "Epoch: 1300, Loss in training: [1955.4126], loss in validation: [1984.3068].\n",
      "Epoch: 1400, Loss in training: [1952.8978], loss in validation: [1979.5533].\n",
      "Epoch: 1500, Loss in training: [1953.0256], loss in validation: [1979.5908].\n",
      "Epoch: 1600, Loss in training: [1947.6501], loss in validation: [1973.0225].\n",
      "5.91\n",
      "num_epoch: 1600, num_cycles: 4, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1973.0225], loss in training: [1947.6501].\n",
      "Epoch: 100, Loss in training: [1949.7898], loss in validation: [1975.1526].\n",
      "Epoch: 200, Loss in training: [1943.3796], loss in validation: [1967.242].\n",
      "Epoch: 300, Loss in training: [1952.1692], loss in validation: [1977.2983].\n",
      "Epoch: 400, Loss in training: [1962.439], loss in validation: [1988.3364].\n",
      "Epoch: 500, Loss in training: [1954.062], loss in validation: [1978.9272].\n",
      "Epoch: 600, Loss in training: [1956.1573], loss in validation: [1982.1464].\n",
      "Epoch: 700, Loss in training: [1947.6538], loss in validation: [1971.848].\n",
      "Epoch: 800, Loss in training: [1947.275], loss in validation: [1970.6158].\n",
      "Epoch: 900, Loss in training: [1952.7528], loss in validation: [1976.4196].\n",
      "Epoch: 1000, Loss in training: [1953.215], loss in validation: [1978.4135].\n",
      "Epoch: 1100, Loss in training: [1955.707], loss in validation: [1981.7935].\n",
      "Epoch: 1200, Loss in training: [1948.6616], loss in validation: [1974.5356].\n",
      "Epoch: 1300, Loss in training: [1954.6613], loss in validation: [1977.6895].\n",
      "Epoch: 1400, Loss in training: [1952.3123], loss in validation: [1978.1486].\n",
      "Epoch: 1500, Loss in training: [1952.9524], loss in validation: [1977.6824].\n",
      "Epoch: 1600, Loss in training: [1953.0792], loss in validation: [1978.612].\n",
      "5.79\n",
      "num_epoch: 1600, num_cycles: 5, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1978.612], loss in training: [1953.0792].\n",
      "Epoch: 100, Loss in training: [1980.0774], loss in validation: [2008.5272].\n",
      "Epoch: 200, Loss in training: [1960.9875], loss in validation: [1989.166].\n",
      "Epoch: 300, Loss in training: [1986.6143], loss in validation: [2015.7646].\n",
      "Epoch: 400, Loss in training: [1945.9734], loss in validation: [1970.0688].\n",
      "Epoch: 500, Loss in training: [1955.7378], loss in validation: [1980.7612].\n",
      "Epoch: 600, Loss in training: [1942.751], loss in validation: [1966.8112].\n",
      "Epoch: 700, Loss in training: [1964.2504], loss in validation: [1991.5776].\n",
      "Epoch: 800, Loss in training: [1945.096], loss in validation: [1972.0464].\n",
      "Epoch: 900, Loss in training: [1962.2936], loss in validation: [1988.2292].\n",
      "Epoch: 1000, Loss in training: [1959.5726], loss in validation: [1984.2512].\n",
      "Epoch: 1100, Loss in training: [1957.2876], loss in validation: [1984.793].\n",
      "Epoch: 1200, Loss in training: [1945.5836], loss in validation: [1969.742].\n",
      "Epoch: 1300, Loss in training: [1936.9606], loss in validation: [1961.7164].\n",
      "Epoch: 1400, Loss in training: [1950.3212], loss in validation: [1977.7].\n",
      "Epoch: 1500, Loss in training: [1948.7603], loss in validation: [1972.3854].\n",
      "Epoch: 1600, Loss in training: [1966.0201], loss in validation: [1992.078].\n",
      "5.86\n",
      "num_epoch: 1600, num_cycles: 5, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1992.078], loss in training: [1966.0201].\n",
      "Epoch: 100, Loss in training: [1968.2115], loss in validation: [1994.27].\n",
      "Epoch: 200, Loss in training: [1956.7366], loss in validation: [1984.3308].\n",
      "Epoch: 300, Loss in training: [1952.3073], loss in validation: [1977.9918].\n",
      "Epoch: 400, Loss in training: [1967.5828], loss in validation: [1993.7626].\n",
      "Epoch: 500, Loss in training: [1946.0931], loss in validation: [1969.88].\n",
      "Epoch: 600, Loss in training: [1964.6176], loss in validation: [1988.7258].\n",
      "Epoch: 700, Loss in training: [1957.9677], loss in validation: [1984.2742].\n",
      "Epoch: 800, Loss in training: [1948.142], loss in validation: [1972.195].\n",
      "Epoch: 900, Loss in training: [1952.482], loss in validation: [1977.6522].\n",
      "Epoch: 1000, Loss in training: [1968.5574], loss in validation: [1994.809].\n",
      "Epoch: 1100, Loss in training: [1954.5928], loss in validation: [1981.3896].\n",
      "Epoch: 1200, Loss in training: [1949.1882], loss in validation: [1972.7506].\n",
      "Epoch: 1300, Loss in training: [1945.3544], loss in validation: [1968.7701].\n",
      "Epoch: 1400, Loss in training: [1954.2706], loss in validation: [1980.1138].\n",
      "Epoch: 1500, Loss in training: [1959.3184], loss in validation: [1983.294].\n",
      "Epoch: 1600, Loss in training: [1949.882], loss in validation: [1973.4542].\n",
      "5.71\n",
      "num_epoch: 1600, num_cycles: 5, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1973.4542], loss in training: [1949.882].\n",
      "Epoch: 100, Loss in training: [1948.7242], loss in validation: [1974.4028].\n",
      "Epoch: 200, Loss in training: [1942.605], loss in validation: [1966.4862].\n",
      "Epoch: 300, Loss in training: [1959.6456], loss in validation: [1984.534].\n",
      "Epoch: 400, Loss in training: [1953.1846], loss in validation: [1978.526].\n",
      "Epoch: 500, Loss in training: [1953.9775], loss in validation: [1980.205].\n",
      "Epoch: 600, Loss in training: [1946.0164], loss in validation: [1969.6036].\n",
      "Epoch: 700, Loss in training: [1954.3746], loss in validation: [1978.507].\n",
      "Epoch: 800, Loss in training: [1948.5702], loss in validation: [1974.848].\n",
      "Epoch: 900, Loss in training: [1952.812], loss in validation: [1978.3177].\n",
      "Epoch: 1000, Loss in training: [1953.3029], loss in validation: [1978.282].\n",
      "Epoch: 1100, Loss in training: [1942.6827], loss in validation: [1966.5656].\n",
      "Epoch: 1200, Loss in training: [1951.4434], loss in validation: [1975.6384].\n",
      "Epoch: 1300, Loss in training: [1970.3044], loss in validation: [1995.898].\n",
      "Epoch: 1400, Loss in training: [1969.5529], loss in validation: [1996.3835].\n",
      "Epoch: 1500, Loss in training: [1948.3354], loss in validation: [1975.4396].\n",
      "Epoch: 1600, Loss in training: [1951.8096], loss in validation: [1975.2146].\n",
      "5.84\n",
      "num_epoch: 1600, num_cycles: 5, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1975.2146], loss in training: [1951.8096].\n",
      "Epoch: 100, Loss in training: [1951.916], loss in validation: [1977.4012].\n",
      "Epoch: 200, Loss in training: [1949.1187], loss in validation: [1973.878].\n",
      "Epoch: 300, Loss in training: [1950.013], loss in validation: [1974.9731].\n",
      "Epoch: 400, Loss in training: [1946.306], loss in validation: [1969.8176].\n",
      "Epoch: 500, Loss in training: [1950.9001], loss in validation: [1977.0507].\n",
      "Epoch: 600, Loss in training: [1949.3759], loss in validation: [1972.6984].\n",
      "Epoch: 700, Loss in training: [1949.472], loss in validation: [1973.9506].\n",
      "Epoch: 800, Loss in training: [1942.5444], loss in validation: [1966.4688].\n",
      "Epoch: 900, Loss in training: [1957.7205], loss in validation: [1983.1632].\n",
      "Epoch: 1000, Loss in training: [1954.1232], loss in validation: [1979.6294].\n",
      "Epoch: 1100, Loss in training: [1954.6488], loss in validation: [1979.0999].\n",
      "Epoch: 1200, Loss in training: [1952.2092], loss in validation: [1977.0084].\n",
      "Epoch: 1300, Loss in training: [1943.7604], loss in validation: [1968.8716].\n",
      "Epoch: 1400, Loss in training: [1953.1726], loss in validation: [1979.1602].\n",
      "Epoch: 1500, Loss in training: [1966.5767], loss in validation: [1993.8948].\n",
      "Epoch: 1600, Loss in training: [1947.3906], loss in validation: [1972.4001].\n",
      "5.8\n",
      "num_epoch: 1600, num_cycles: 10, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1972.4001], loss in training: [1947.3906].\n",
      "Epoch: 100, Loss in training: [1962.6248], loss in validation: [1989.3431].\n",
      "Epoch: 200, Loss in training: [1952.3337], loss in validation: [1976.3376].\n",
      "Epoch: 300, Loss in training: [1949.7017], loss in validation: [1974.0544].\n",
      "Epoch: 400, Loss in training: [1956.8763], loss in validation: [1981.8868].\n",
      "Epoch: 500, Loss in training: [2009.567], loss in validation: [2036.2062].\n",
      "Epoch: 600, Loss in training: [1947.0627], loss in validation: [1971.3768].\n",
      "Epoch: 700, Loss in training: [1955.4742], loss in validation: [1982.2795].\n",
      "Epoch: 800, Loss in training: [1953.2988], loss in validation: [1979.9056].\n",
      "Epoch: 900, Loss in training: [1947.7155], loss in validation: [1972.6115].\n",
      "Epoch: 1000, Loss in training: [1958.0286], loss in validation: [1985.0112].\n",
      "Epoch: 1100, Loss in training: [1949.346], loss in validation: [1973.6946].\n",
      "Epoch: 1200, Loss in training: [1951.9644], loss in validation: [1976.2948].\n",
      "Epoch: 1300, Loss in training: [1937.5466], loss in validation: [1961.143].\n",
      "Epoch: 1400, Loss in training: [1949.4615], loss in validation: [1974.0554].\n",
      "Epoch: 1500, Loss in training: [1958.093], loss in validation: [1986.2325].\n",
      "Epoch: 1600, Loss in training: [1949.8442], loss in validation: [1973.5981].\n",
      "5.83\n",
      "num_epoch: 1600, num_cycles: 10, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1973.5981], loss in training: [1949.8442].\n",
      "Epoch: 100, Loss in training: [1949.4135], loss in validation: [1973.9376].\n",
      "Epoch: 200, Loss in training: [1955.4934], loss in validation: [1983.4156].\n",
      "Epoch: 300, Loss in training: [1949.1268], loss in validation: [1974.4816].\n",
      "Epoch: 400, Loss in training: [1944.9584], loss in validation: [1969.9045].\n",
      "Epoch: 500, Loss in training: [1935.1516], loss in validation: [1957.8158].\n",
      "Epoch: 600, Loss in training: [1956.2678], loss in validation: [1981.7222].\n",
      "Epoch: 700, Loss in training: [1942.6434], loss in validation: [1967.7208].\n",
      "Epoch: 800, Loss in training: [1945.2742], loss in validation: [1967.9828].\n",
      "Epoch: 900, Loss in training: [1955.6044], loss in validation: [1979.9073].\n",
      "Epoch: 1000, Loss in training: [1943.7476], loss in validation: [1969.2917].\n",
      "Epoch: 1100, Loss in training: [1945.2184], loss in validation: [1971.5436].\n",
      "Epoch: 1200, Loss in training: [1957.3516], loss in validation: [1979.6448].\n",
      "Epoch: 1300, Loss in training: [1967.4362], loss in validation: [1994.1292].\n",
      "Epoch: 1400, Loss in training: [1950.5404], loss in validation: [1975.6866].\n",
      "Epoch: 1500, Loss in training: [1949.9865], loss in validation: [1975.6696].\n",
      "Epoch: 1600, Loss in training: [1945.7714], loss in validation: [1970.5164].\n",
      "5.81\n",
      "num_epoch: 1600, num_cycles: 10, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1970.5164], loss in training: [1945.7714].\n",
      "Epoch: 100, Loss in training: [1948.6528], loss in validation: [1973.715].\n",
      "Epoch: 200, Loss in training: [1947.5706], loss in validation: [1972.7288].\n",
      "Epoch: 300, Loss in training: [1958.3322], loss in validation: [1983.1238].\n",
      "Epoch: 400, Loss in training: [1946.8638], loss in validation: [1971.5718].\n",
      "Epoch: 500, Loss in training: [1942.6674], loss in validation: [1969.6478].\n",
      "Epoch: 600, Loss in training: [1941.985], loss in validation: [1966.1246].\n",
      "Epoch: 700, Loss in training: [1946.7146], loss in validation: [1971.2828].\n",
      "Epoch: 800, Loss in training: [1946.4705], loss in validation: [1969.6624].\n",
      "Epoch: 900, Loss in training: [1954.3558], loss in validation: [1977.3394].\n",
      "Epoch: 1000, Loss in training: [1946.3942], loss in validation: [1973.0052].\n",
      "Epoch: 1100, Loss in training: [1950.4536], loss in validation: [1977.1652].\n",
      "Epoch: 1200, Loss in training: [1975.5406], loss in validation: [2002.777].\n",
      "Epoch: 1300, Loss in training: [1943.5886], loss in validation: [1969.2552].\n",
      "Epoch: 1400, Loss in training: [1950.522], loss in validation: [1975.3177].\n",
      "Epoch: 1500, Loss in training: [1949.9816], loss in validation: [1975.1312].\n",
      "Epoch: 1600, Loss in training: [1949.3326], loss in validation: [1974.3304].\n",
      "5.79\n",
      "num_epoch: 1600, num_cycles: 10, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1974.3304], loss in training: [1949.3326].\n",
      "Epoch: 100, Loss in training: [1946.2819], loss in validation: [1972.4886].\n",
      "Epoch: 200, Loss in training: [1942.0916], loss in validation: [1966.3096].\n",
      "Epoch: 300, Loss in training: [1942.4766], loss in validation: [1966.0413].\n",
      "Epoch: 400, Loss in training: [1944.2764], loss in validation: [1969.0507].\n",
      "Epoch: 500, Loss in training: [1966.3466], loss in validation: [1992.858].\n",
      "Epoch: 600, Loss in training: [1945.5878], loss in validation: [1970.897].\n",
      "Epoch: 700, Loss in training: [1956.4916], loss in validation: [1983.1398].\n",
      "Epoch: 800, Loss in training: [1948.3994], loss in validation: [1973.8372].\n",
      "Epoch: 900, Loss in training: [1954.2478], loss in validation: [1979.9521].\n",
      "Epoch: 1000, Loss in training: [1950.9467], loss in validation: [1974.33].\n",
      "Epoch: 1100, Loss in training: [1940.651], loss in validation: [1964.2039].\n",
      "Epoch: 1200, Loss in training: [1947.207], loss in validation: [1972.4493].\n",
      "Epoch: 1300, Loss in training: [1950.9098], loss in validation: [1976.4886].\n",
      "Epoch: 1400, Loss in training: [1954.9576], loss in validation: [1979.7249].\n",
      "Epoch: 1500, Loss in training: [1951.387], loss in validation: [1975.8638].\n",
      "Epoch: 1600, Loss in training: [1947.5739], loss in validation: [1970.841].\n",
      "Epoch: 1700, Loss in training: [1955.9904], loss in validation: [1983.0526].\n",
      "Epoch: 1800, Loss in training: [1953.1876], loss in validation: [1978.3262].\n",
      "Epoch: 1900, Loss in training: [1950.2566], loss in validation: [1977.0295].\n",
      "Epoch: 2000, Loss in training: [1950.9622], loss in validation: [1975.8708].\n",
      "7.28\n",
      "num_epoch: 2000, num_cycles: 2, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1975.8708], loss in training: [1950.9622].\n",
      "Epoch: 100, Loss in training: [1951.6514], loss in validation: [1979.4774].\n",
      "Epoch: 200, Loss in training: [1940.6978], loss in validation: [1966.0652].\n",
      "Epoch: 300, Loss in training: [1944.1501], loss in validation: [1969.278].\n",
      "Epoch: 400, Loss in training: [1960.5416], loss in validation: [1985.913].\n",
      "Epoch: 500, Loss in training: [1946.2896], loss in validation: [1970.6614].\n",
      "Epoch: 600, Loss in training: [1947.4095], loss in validation: [1971.8118].\n",
      "Epoch: 700, Loss in training: [1947.6519], loss in validation: [1971.3156].\n",
      "Epoch: 800, Loss in training: [1953.1832], loss in validation: [1978.274].\n",
      "Epoch: 900, Loss in training: [1949.8248], loss in validation: [1975.7249].\n",
      "Epoch: 1000, Loss in training: [1957.575], loss in validation: [1982.9078].\n",
      "Epoch: 1100, Loss in training: [1947.4756], loss in validation: [1972.6652].\n",
      "Epoch: 1200, Loss in training: [1950.1116], loss in validation: [1976.7725].\n",
      "Epoch: 1300, Loss in training: [1943.6674], loss in validation: [1967.3492].\n",
      "Epoch: 1400, Loss in training: [1966.2476], loss in validation: [1989.4592].\n",
      "Epoch: 1500, Loss in training: [1955.6962], loss in validation: [1980.1993].\n",
      "Epoch: 1600, Loss in training: [1950.4644], loss in validation: [1974.349].\n",
      "Epoch: 1700, Loss in training: [1946.6852], loss in validation: [1971.3962].\n",
      "Epoch: 1800, Loss in training: [1955.9214], loss in validation: [1981.0182].\n",
      "Epoch: 1900, Loss in training: [1944.6118], loss in validation: [1968.7098].\n",
      "Epoch: 2000, Loss in training: [1966.8597], loss in validation: [1989.6154].\n",
      "7.45\n",
      "num_epoch: 2000, num_cycles: 2, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1989.6154], loss in training: [1966.8597].\n",
      "Epoch: 100, Loss in training: [1955.8352], loss in validation: [1984.944].\n",
      "Epoch: 200, Loss in training: [1935.3636], loss in validation: [1959.95].\n",
      "Epoch: 300, Loss in training: [1955.5632], loss in validation: [1980.5576].\n",
      "Epoch: 400, Loss in training: [1938.1768], loss in validation: [1964.0352].\n",
      "Epoch: 500, Loss in training: [1952.937], loss in validation: [1977.823].\n",
      "Epoch: 600, Loss in training: [1945.8964], loss in validation: [1969.8152].\n",
      "Epoch: 700, Loss in training: [1947.2926], loss in validation: [1971.6818].\n",
      "Epoch: 800, Loss in training: [1958.1252], loss in validation: [1983.2942].\n",
      "Epoch: 900, Loss in training: [1959.6008], loss in validation: [1984.9272].\n",
      "Epoch: 1000, Loss in training: [1951.2296], loss in validation: [1976.1744].\n",
      "Epoch: 1100, Loss in training: [1945.6938], loss in validation: [1971.8862].\n",
      "Epoch: 1200, Loss in training: [1941.5743], loss in validation: [1966.16].\n",
      "Epoch: 1300, Loss in training: [1954.2205], loss in validation: [1981.0116].\n",
      "Epoch: 1400, Loss in training: [1950.8906], loss in validation: [1976.5056].\n",
      "Epoch: 1500, Loss in training: [1945.0664], loss in validation: [1970.0796].\n",
      "Epoch: 1600, Loss in training: [1949.1927], loss in validation: [1976.2542].\n",
      "Epoch: 1700, Loss in training: [1946.6002], loss in validation: [1971.0914].\n",
      "Epoch: 1800, Loss in training: [1948.9865], loss in validation: [1974.0994].\n",
      "Epoch: 1900, Loss in training: [1953.762], loss in validation: [1977.9556].\n",
      "Epoch: 2000, Loss in training: [1950.9836], loss in validation: [1975.0876].\n",
      "7.23\n",
      "num_epoch: 2000, num_cycles: 2, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1975.0876], loss in training: [1950.9836].\n",
      "Epoch: 100, Loss in training: [1966.4114], loss in validation: [1997.181].\n",
      "Epoch: 200, Loss in training: [1942.5529], loss in validation: [1965.5886].\n",
      "Epoch: 300, Loss in training: [1946.7106], loss in validation: [1972.0548].\n",
      "Epoch: 400, Loss in training: [1964.2894], loss in validation: [1986.1594].\n",
      "Epoch: 500, Loss in training: [1959.2646], loss in validation: [1983.212].\n",
      "Epoch: 600, Loss in training: [1944.6664], loss in validation: [1970.0956].\n",
      "Epoch: 700, Loss in training: [1951.6945], loss in validation: [1976.804].\n",
      "Epoch: 800, Loss in training: [1946.9333], loss in validation: [1970.1086].\n",
      "Epoch: 900, Loss in training: [1946.2137], loss in validation: [1971.6086].\n",
      "Epoch: 1000, Loss in training: [1949.2854], loss in validation: [1974.8759].\n",
      "Epoch: 1100, Loss in training: [1940.135], loss in validation: [1964.7961].\n",
      "Epoch: 1200, Loss in training: [1954.0918], loss in validation: [1980.2974].\n",
      "Epoch: 1300, Loss in training: [1980.821], loss in validation: [2002.527].\n",
      "Epoch: 1400, Loss in training: [1946.4764], loss in validation: [1972.3138].\n",
      "Epoch: 1500, Loss in training: [1949.0887], loss in validation: [1976.3662].\n",
      "Epoch: 1600, Loss in training: [1941.2402], loss in validation: [1964.3472].\n",
      "Epoch: 1700, Loss in training: [1947.769], loss in validation: [1972.184].\n",
      "Epoch: 1800, Loss in training: [1948.7996], loss in validation: [1974.1196].\n",
      "Epoch: 1900, Loss in training: [1947.1086], loss in validation: [1971.6674].\n",
      "Epoch: 2000, Loss in training: [1950.3922], loss in validation: [1973.2892].\n",
      "7.24\n",
      "num_epoch: 2000, num_cycles: 2, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1973.2892], loss in training: [1950.3922].\n",
      "Epoch: 100, Loss in training: [1966.3997], loss in validation: [1994.5284].\n",
      "Epoch: 200, Loss in training: [1944.3508], loss in validation: [1968.384].\n",
      "Epoch: 300, Loss in training: [1944.165], loss in validation: [1968.3615].\n",
      "Epoch: 400, Loss in training: [1943.9174], loss in validation: [1968.0752].\n",
      "Epoch: 500, Loss in training: [1971.4802], loss in validation: [1996.4222].\n",
      "Epoch: 600, Loss in training: [1944.356], loss in validation: [1969.8278].\n",
      "Epoch: 700, Loss in training: [1964.6523], loss in validation: [1989.7578].\n",
      "Epoch: 800, Loss in training: [1952.1053], loss in validation: [1978.0354].\n",
      "Epoch: 900, Loss in training: [1944.8597], loss in validation: [1970.1666].\n",
      "Epoch: 1000, Loss in training: [1949.0588], loss in validation: [1974.2957].\n",
      "Epoch: 1100, Loss in training: [1974.8038], loss in validation: [2004.0828].\n",
      "Epoch: 1200, Loss in training: [1958.3226], loss in validation: [1983.842].\n",
      "Epoch: 1300, Loss in training: [1954.8298], loss in validation: [1979.6569].\n",
      "Epoch: 1400, Loss in training: [1963.7238], loss in validation: [1989.2806].\n",
      "Epoch: 1500, Loss in training: [1957.9236], loss in validation: [1984.343].\n",
      "Epoch: 1600, Loss in training: [1950.0662], loss in validation: [1975.1946].\n",
      "Epoch: 1700, Loss in training: [1948.9478], loss in validation: [1976.0356].\n",
      "Epoch: 1800, Loss in training: [1950.6052], loss in validation: [1976.7094].\n",
      "Epoch: 1900, Loss in training: [1949.4706], loss in validation: [1974.0216].\n",
      "Epoch: 2000, Loss in training: [1946.9708], loss in validation: [1971.7998].\n",
      "7.24\n",
      "num_epoch: 2000, num_cycles: 4, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1971.7998], loss in training: [1946.9708].\n",
      "Epoch: 100, Loss in training: [1946.3392], loss in validation: [1971.8354].\n",
      "Epoch: 200, Loss in training: [1945.7192], loss in validation: [1970.6357].\n",
      "Epoch: 300, Loss in training: [1947.6478], loss in validation: [1971.1234].\n",
      "Epoch: 400, Loss in training: [1946.7192], loss in validation: [1970.6434].\n",
      "Epoch: 500, Loss in training: [1946.4636], loss in validation: [1971.0676].\n",
      "Epoch: 600, Loss in training: [1955.0764], loss in validation: [1982.695].\n",
      "Epoch: 700, Loss in training: [1964.249], loss in validation: [1990.4648].\n",
      "Epoch: 800, Loss in training: [1944.0269], loss in validation: [1968.6761].\n",
      "Epoch: 900, Loss in training: [1944.8022], loss in validation: [1967.8466].\n",
      "Epoch: 1000, Loss in training: [1947.2908], loss in validation: [1971.2582].\n",
      "Epoch: 1100, Loss in training: [1946.8032], loss in validation: [1970.6578].\n",
      "Epoch: 1200, Loss in training: [1958.783], loss in validation: [1982.7548].\n",
      "Epoch: 1300, Loss in training: [1952.8542], loss in validation: [1976.6403].\n",
      "Epoch: 1400, Loss in training: [1956.4471], loss in validation: [1983.6798].\n",
      "Epoch: 1500, Loss in training: [1947.4001], loss in validation: [1970.5822].\n",
      "Epoch: 1600, Loss in training: [1946.8378], loss in validation: [1971.811].\n",
      "Epoch: 1700, Loss in training: [1946.1595], loss in validation: [1970.6984].\n",
      "Epoch: 1800, Loss in training: [1950.907], loss in validation: [1974.4471].\n",
      "Epoch: 1900, Loss in training: [1958.0946], loss in validation: [1981.3702].\n",
      "Epoch: 2000, Loss in training: [1946.0454], loss in validation: [1970.9008].\n",
      "7.25\n",
      "num_epoch: 2000, num_cycles: 4, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1970.9008], loss in training: [1946.0454].\n",
      "Epoch: 100, Loss in training: [1949.267], loss in validation: [1976.6594].\n",
      "Epoch: 200, Loss in training: [1942.9622], loss in validation: [1966.913].\n",
      "Epoch: 300, Loss in training: [1941.6948], loss in validation: [1965.5856].\n",
      "Epoch: 400, Loss in training: [1963.7214], loss in validation: [1987.859].\n",
      "Epoch: 500, Loss in training: [1946.1482], loss in validation: [1969.8038].\n",
      "Epoch: 600, Loss in training: [1948.2258], loss in validation: [1974.0308].\n",
      "Epoch: 700, Loss in training: [1945.6971], loss in validation: [1969.0396].\n",
      "Epoch: 800, Loss in training: [1946.9128], loss in validation: [1971.5402].\n",
      "Epoch: 900, Loss in training: [1944.4847], loss in validation: [1968.4874].\n",
      "Epoch: 1000, Loss in training: [1953.0767], loss in validation: [1979.2162].\n",
      "Epoch: 1100, Loss in training: [1940.1318], loss in validation: [1963.3666].\n",
      "Epoch: 1200, Loss in training: [1950.968], loss in validation: [1974.749].\n",
      "Epoch: 1300, Loss in training: [1952.4508], loss in validation: [1978.366].\n",
      "Epoch: 1400, Loss in training: [1952.7728], loss in validation: [1978.7751].\n",
      "Epoch: 1500, Loss in training: [1953.176], loss in validation: [1977.1562].\n",
      "Epoch: 1600, Loss in training: [1948.5646], loss in validation: [1975.581].\n",
      "Epoch: 1700, Loss in training: [1961.2822], loss in validation: [1985.4644].\n",
      "Epoch: 1800, Loss in training: [1949.083], loss in validation: [1974.3383].\n",
      "Epoch: 1900, Loss in training: [1946.2144], loss in validation: [1970.1108].\n",
      "Epoch: 2000, Loss in training: [1956.77], loss in validation: [1980.5142].\n",
      "7.31\n",
      "num_epoch: 2000, num_cycles: 4, cutting_ratio: 0.7.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1980.5142], loss in training: [1956.77].\n",
      "Epoch: 100, Loss in training: [1958.3885], loss in validation: [1985.069].\n",
      "Epoch: 200, Loss in training: [1946.4698], loss in validation: [1970.566].\n",
      "Epoch: 300, Loss in training: [1944.3016], loss in validation: [1968.1711].\n",
      "Epoch: 400, Loss in training: [1947.385], loss in validation: [1972.4302].\n",
      "Epoch: 500, Loss in training: [1947.3588], loss in validation: [1971.856].\n",
      "Epoch: 600, Loss in training: [1946.2498], loss in validation: [1970.7156].\n",
      "Epoch: 700, Loss in training: [1943.5994], loss in validation: [1967.2074].\n",
      "Epoch: 800, Loss in training: [1969.405], loss in validation: [1995.353].\n",
      "Epoch: 900, Loss in training: [1953.837], loss in validation: [1980.4124].\n",
      "Epoch: 1000, Loss in training: [1949.621], loss in validation: [1973.8052].\n",
      "Epoch: 1100, Loss in training: [1936.9282], loss in validation: [1961.5758].\n",
      "Epoch: 1200, Loss in training: [1947.1078], loss in validation: [1972.4034].\n",
      "Epoch: 1300, Loss in training: [1947.9462], loss in validation: [1973.8105].\n",
      "Epoch: 1400, Loss in training: [1951.9772], loss in validation: [1978.3741].\n",
      "Epoch: 1500, Loss in training: [1956.2574], loss in validation: [1981.2114].\n",
      "Epoch: 1600, Loss in training: [1940.8508], loss in validation: [1966.4354].\n",
      "Epoch: 1700, Loss in training: [1944.939], loss in validation: [1970.6702].\n",
      "Epoch: 1800, Loss in training: [1949.3582], loss in validation: [1975.9072].\n",
      "Epoch: 1900, Loss in training: [1949.4366], loss in validation: [1973.682].\n",
      "Epoch: 2000, Loss in training: [1954.2222], loss in validation: [1981.135].\n",
      "7.29\n",
      "num_epoch: 2000, num_cycles: 4, cutting_ratio: 0.9.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1981.135], loss in training: [1954.2222].\n",
      "Epoch: 100, Loss in training: [1956.1578], loss in validation: [1983.4478].\n",
      "Epoch: 200, Loss in training: [1946.6125], loss in validation: [1972.1058].\n",
      "Epoch: 300, Loss in training: [1948.5728], loss in validation: [1972.9738].\n",
      "Epoch: 400, Loss in training: [1953.1656], loss in validation: [1978.1758].\n",
      "Epoch: 500, Loss in training: [1947.93], loss in validation: [1975.139].\n",
      "Epoch: 600, Loss in training: [1945.9058], loss in validation: [1969.9238].\n",
      "Epoch: 700, Loss in training: [1947.0573], loss in validation: [1972.2].\n",
      "Epoch: 800, Loss in training: [1956.1823], loss in validation: [1981.379].\n",
      "Epoch: 900, Loss in training: [1957.691], loss in validation: [1985.6716].\n",
      "Epoch: 1000, Loss in training: [1950.9606], loss in validation: [1976.7734].\n",
      "Epoch: 1100, Loss in training: [1952.8499], loss in validation: [1976.76].\n",
      "Epoch: 1200, Loss in training: [1957.4781], loss in validation: [1983.5842].\n",
      "Epoch: 1300, Loss in training: [1959.4333], loss in validation: [1987.5212].\n",
      "Epoch: 1400, Loss in training: [1946.3162], loss in validation: [1970.7598].\n",
      "Epoch: 1500, Loss in training: [1948.8402], loss in validation: [1973.537].\n",
      "Epoch: 1600, Loss in training: [1954.2208], loss in validation: [1979.1143].\n",
      "Epoch: 1700, Loss in training: [1947.566], loss in validation: [1972.5345].\n",
      "Epoch: 1800, Loss in training: [1949.065], loss in validation: [1973.7438].\n",
      "Epoch: 1900, Loss in training: [1946.1482], loss in validation: [1970.6707].\n",
      "Epoch: 2000, Loss in training: [1955.8262], loss in validation: [1981.2496].\n",
      "7.22\n",
      "num_epoch: 2000, num_cycles: 5, cutting_ratio: 0.3.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1981.2496], loss in training: [1955.8262].\n",
      "Epoch: 100, Loss in training: [1954.9991], loss in validation: [1980.1667].\n",
      "Epoch: 200, Loss in training: [1945.023], loss in validation: [1968.583].\n",
      "Epoch: 300, Loss in training: [1949.2338], loss in validation: [1974.4816].\n",
      "Epoch: 400, Loss in training: [1953.6334], loss in validation: [1978.4229].\n",
      "Epoch: 500, Loss in training: [1942.077], loss in validation: [1967.6573].\n",
      "Epoch: 600, Loss in training: [1947.985], loss in validation: [1973.2764].\n",
      "Epoch: 700, Loss in training: [1953.0955], loss in validation: [1978.3256].\n",
      "Epoch: 800, Loss in training: [1949.2916], loss in validation: [1973.7098].\n",
      "Epoch: 900, Loss in training: [1948.7664], loss in validation: [1973.6208].\n",
      "Epoch: 1000, Loss in training: [1952.8156], loss in validation: [1978.055].\n",
      "Epoch: 1100, Loss in training: [1946.7198], loss in validation: [1971.2224].\n",
      "Epoch: 1200, Loss in training: [1946.9539], loss in validation: [1972.6788].\n",
      "Epoch: 1300, Loss in training: [1944.8732], loss in validation: [1970.0012].\n",
      "Epoch: 1400, Loss in training: [1945.144], loss in validation: [1970.6752].\n",
      "Epoch: 1500, Loss in training: [1952.9279], loss in validation: [1977.9528].\n",
      "Epoch: 1600, Loss in training: [1945.7416], loss in validation: [1969.5712].\n",
      "Epoch: 1700, Loss in training: [1960.5314], loss in validation: [1987.2028].\n",
      "Epoch: 1800, Loss in training: [1944.665], loss in validation: [1968.4672].\n",
      "Epoch: 1900, Loss in training: [1946.4376], loss in validation: [1970.2012].\n",
      "Epoch: 2000, Loss in training: [1948.431], loss in validation: [1973.026].\n",
      "7.52\n",
      "num_epoch: 2000, num_cycles: 5, cutting_ratio: 0.5.\n",
      "L2: 0.1, LR: 0.1, z_dim: 8, loss in validation: [1973.026], loss in training: [1948.431].\n",
      "Epoch: 100, Loss in training: [1951.4728], loss in validation: [1976.5577].\n",
      "Epoch: 200, Loss in training: [1961.072], loss in validation: [1989.9261].\n",
      "Epoch: 300, Loss in training: [1951.4216], loss in validation: [1976.8746].\n",
      "Epoch: 400, Loss in training: [1955.981], loss in validation: [1983.1608].\n",
      "Epoch: 500, Loss in training: [1942.805], loss in validation: [1967.2826].\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "opt_l2 = 0.\n",
    "opt_lr = 0.\n",
    "opt_dim = 0\n",
    "opt_epoch_num = 0.\n",
    "opt_num_cycle = 0.\n",
    "opt_cr = 0.\n",
    "opt_loss = torch.Tensor([float(\"Inf\")])\n",
    "if torch.cuda.is_available():\n",
    "    opt_loss = opt_loss.cuda()\n",
    "for l2 in L2_Lambda:\n",
    "    for lr in Initial_Learning_Rate:\n",
    "        for Z in z_dim:\n",
    "            for Epoch_num in EPOCH_NUM:\n",
    "                for Num_cycles in NUM_CYCLES:\n",
    "                    for cutting_ratio in CUTTING_RATIO:\n",
    "                        _, _, _, _, train_loss_unsup, eval_loss_unsup = train_KL_PMVAE(x_train_gene, x_train_mirna, x_valid_gene, x_valid_mirna,\n",
    "                                                                                       Z, input_n1, input_n2, pathway_mask_tune,\n",
    "                                                                                       lr, l2, cutting_ratio, Epoch_num, Num_cycles, dtype,\n",
    "                                                                                       path = \"saved_models/unsup_checkpoint_tune.pt\")\n",
    "            \n",
    "                        if eval_loss_unsup < opt_loss:\n",
    "                            opt_l2 = l2\n",
    "                            opt_lr = lr\n",
    "                            opt_dim = Z\n",
    "                            opt_epoch_num = Epoch_num\n",
    "                            opt_num_cycle = Num_cycles\n",
    "                            opt_cr = cutting_ratio\n",
    "                            opt_loss = eval_loss_unsup\n",
    "                        print(\"num_epoch: %s,\" %Epoch_num, \"num_cycles: %s,\" %Num_cycles, \"cutting_ratio: %s.\" %cutting_ratio)\n",
    "                        print(\"L2: %s,\" %l2, \"LR: %s,\" %lr, \"z_dim: %s,\" %Z, \"loss in validation: %s,\" %np.array(eval_loss_unsup.detach().cpu().numpy()).round(4), \"loss in training: %s.\" %np.array(train_loss_unsup.detach().cpu().numpy()).round(4))\n",
    "end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "535c1d81-8437-445b-bb52-eeeb174ec0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal num epoch: 2400, optimal num cycles: 2, optimal cutting ratio: 0.3.\n",
      "Optimal L2: 0.005, optimal LR: 0.005, optimal z_dim: 16.\n",
      "--- 40650.24967002869 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal num epoch: %s,\" %opt_epoch_num, \"optimal num cycles: %s,\" %opt_num_cycle, \"optimal cutting ratio: %s.\" %opt_cr)\n",
    "print(\"Optimal L2: %s,\" %opt_l2, \"optimal LR: %s,\" %opt_lr, \"optimal z_dim: %s.\" %opt_dim)\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f658be-43f0-407a-9152-562e89f0631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running time 11.3-12.8 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5cd9b-3fe4-4a6a-851a-80cc4c6be3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# %%time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "opt_l2 = 0.\n",
    "opt_lr = 0.\n",
    "opt_dim = 0\n",
    "opt_epoch_num = 0.\n",
    "opt_num_cycle = 0.\n",
    "opt_cr = 0.\n",
    "opt_loss = torch.Tensor([float(\"Inf\")])\n",
    "if torch.cuda.is_available():\n",
    "    opt_loss = opt_loss.cuda()\n",
    "for l2 in L2_Lambda:\n",
    "    for lr in Initial_Learning_Rate:\n",
    "        for Z in z_dim:\n",
    "            for Epoch_num in EPOCH_NUM:\n",
    "                for Num_cycles in NUM_CYCLES:\n",
    "                    for cutting_ratio in CUTTING_RATIO:\n",
    "                        _, _, _, _, train_loss_unsup, eval_loss_unsup = train_KL_PMVAE(x_train_gene, x_train_mirna, x_valid_gene, x_valid_mirna,\n",
    "                                                                                       Z, input_n1, input_n2, pathway_mask_tune,\n",
    "                                                                                       lr, l2, cutting_ratio, Epoch_num, Num_cycles, dtype,\n",
    "                                                                                       path = \"saved_models/unsup_checkpoint_tune.pt\")\n",
    "            \n",
    "                        if eval_loss_unsup < opt_loss:\n",
    "                            opt_l2 = l2\n",
    "                            opt_lr = lr\n",
    "                            opt_dim = Z\n",
    "                            opt_epoch_num = Epoch_num\n",
    "                            opt_num_cycle = Num_cycles\n",
    "                            opt_cr = cutting_ratio\n",
    "                            opt_loss = eval_loss_unsup\n",
    "                        print(\"num_epoch: %s,\" %Epoch_num, \"num_cycles: %s,\" %Num_cycles, \"cutting_ratio: %s.\" %cutting_ratio)\n",
    "#                        print(\"L2: %s,\" %l2, \"LR: %s,\" %lr, \"z_dim: %s,\" %Z, \"loss in validation: %s,\" %np.array(eval_loss_unsup.detach().cpu().numpy()).round(4), \"loss in training: %s.\" %np.array(train_loss_unsup.detach().cpu().numpy()).round(4))\n",
    "\n",
    "end_time = time.time()\n",
    "# print(\"Optimal num epoch: %s,\" %opt_epoch_num, \"optimal num cycles: %s,\" %opt_num_cycle, \"optimal cutting ratio: %s.\" %opt_cr)\n",
    "# print(\"Optimal L2: %s,\" %opt_l2, \"optimal LR: %s,\" %opt_lr, \"optimal z_dim: %s.\" %opt_dim)\n",
    "# print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d6fd89d-dd0e-45d8-adc7-4526ff806b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal num epoch: 2400, optimal num cycles: 2, optimal cutting ratio: 0.3.\n",
      "Optimal L2: 0.005, optimal LR: 0.005, optimal z_dim: 16.\n",
      "--- 42799.112855911255 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal num epoch: %s,\" %opt_epoch_num, \"optimal num cycles: %s,\" %opt_num_cycle, \"optimal cutting ratio: %s.\" %opt_cr)\n",
    "print(\"Optimal L2: %s,\" %opt_l2, \"optimal LR: %s,\" %opt_lr, \"optimal z_dim: %s.\" %opt_dim)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89737ff1-9d25-4189-bca1-6fd55d93eba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d35bed2d-9b0c-49aa-b26f-e862529b54ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "/cloud-home/U1039935/Autosurv/autosurv/KL_PMVAE.py:58: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  z = Variable(torch.cuda.FloatTensor(std.size()).normal_(0, 1))\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "993cf54b-6b4d-44b9-be12-1963976446bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss in training: [2039.9526], loss in validation: [2049.2239].\n",
      "Epoch: 200, Loss in training: [1953.9432], loss in validation: [1975.381].\n",
      "Epoch: 300, Loss in training: [1924.0336], loss in validation: [1948.2036].\n",
      "Epoch: 400, Loss in training: [1908.0326], loss in validation: [1933.9738].\n",
      "Epoch: 500, Loss in training: [1898.3835], loss in validation: [1926.075].\n",
      "Epoch: 600, Loss in training: [1893.3428], loss in validation: [1920.6125].\n",
      "Epoch: 700, Loss in training: [1890.231], loss in validation: [1917.8398].\n",
      "Epoch: 800, Loss in training: [1888.1566], loss in validation: [1916.529].\n",
      "Epoch: 900, Loss in training: [1886.7904], loss in validation: [1915.5999].\n",
      "Epoch: 1000, Loss in training: [1885.8164], loss in validation: [1914.7104].\n",
      "Epoch: 1100, Loss in training: [1885.2356], loss in validation: [1913.9022].\n",
      "Epoch: 1200, Loss in training: [1885.11], loss in validation: [1913.4348].\n",
      "Epoch: 1300, Loss in training: [1872.215], loss in validation: [1900.0424].\n",
      "Epoch: 1400, Loss in training: [1877.4344], loss in validation: [1905.6064].\n",
      "Epoch: 1500, Loss in training: [1881.851], loss in validation: [1910.233].\n",
      "Epoch: 1600, Loss in training: [1884.3602], loss in validation: [1913.0667].\n",
      "Epoch: 1700, Loss in training: [1883.9492], loss in validation: [1912.2238].\n",
      "Epoch: 1800, Loss in training: [1884.2078], loss in validation: [1913.3542].\n",
      "Epoch: 1900, Loss in training: [1883.819], loss in validation: [1912.3938].\n",
      "Epoch: 2000, Loss in training: [1883.7522], loss in validation: [1912.4178].\n",
      "Epoch: 2100, Loss in training: [1883.9462], loss in validation: [1912.4731].\n",
      "Epoch: 2200, Loss in training: [1883.852], loss in validation: [1912.7632].\n",
      "Epoch: 2300, Loss in training: [1883.8546], loss in validation: [1912.3002].\n",
      "Epoch: 2400, Loss in training: [1883.6816], loss in validation: [1911.955].\n",
      "Saving model...\n",
      "Model saved.\n",
      "9.08\n",
      "Loss in testing: [1911.955], loss in training: [1883.6816].\n"
     ]
    }
   ],
   "source": [
    "train_mean, train_logvar, test_mean, test_logvar, train_loss_unsup, test_loss_unsup = train_KL_PMVAE(x_train_gene_overall, x_train_mirna_overall, x_test_gene_overall, x_test_mirna_overall,\n",
    "                                                                                                     opt_dim, input_n1, input_n2, pathway_mask_test,\n",
    "                                                                                                     opt_lr, opt_l2, opt_cr, opt_epoch_num, opt_num_cycle, dtype, save_model = True,\n",
    "                                                                                                     path = \"saved_models/unsup_checkpoint_overall.pt\")\n",
    "print(\"Loss in testing: %s,\" %np.array(test_loss_unsup.detach().cpu().numpy()).round(4), \"loss in training: %s.\" %np.array(train_loss_unsup.detach().cpu().numpy()).round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762a2e2-6a0b-4922-9f7e-8c488d94f4d0",
   "metadata": {},
   "source": [
    "Create the data for LFSurv model (tune data & Overall data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "130ce97d-00a6-4eb6-80bf-9b60fb6a5d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size: 857, testing sample size: 201.\n"
     ]
    }
   ],
   "source": [
    "tr_z = train_mean\n",
    "tes_z = test_mean\n",
    "\n",
    "print(\"Training sample size: %s,\" %tr_z.size()[0], \"testing sample size: %s.\" %tes_z.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f3e3810-d060-4324-94cd-9adae1dadaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tr_pre = torch.cat((ytime_train_overall, yevent_train_overall, age_train_overall, stage_i_train_overall, stage_ii_train_overall, race_white_train_overall, tr_z), 1)\n",
    "processed_tes_pre = torch.cat((ytime_test_overall, yevent_test_overall, age_test_overall, stage_i_test_overall, stage_ii_test_overall, race_white_test_overall, tes_z), 1)\n",
    "\n",
    "z_count = np.array(list(range(1, tr_z.size()[1]+1, 1))).astype('str')\n",
    "z_names = np.char.add('Z_', z_count).tolist()\n",
    "\n",
    "processed_tr = pd.DataFrame(processed_tr_pre.detach().cpu(), columns = ['OS.time', 'OS', 'age', 'stage_i', 'stage_ii', 'race_white'] + z_names)\n",
    "processed_tr = processed_tr.astype(float)\n",
    "processed_tr = pd.concat([patient_id_train_overall, processed_tr], axis=1)\n",
    "\n",
    "processed_tes = pd.DataFrame(processed_tes_pre.detach().cpu(), columns = ['OS.time', 'OS', 'age', 'stage_i', 'stage_ii', 'race_white'] + z_names)\n",
    "processed_tes = processed_tes.astype(float)\n",
    "processed_tes = pd.concat([patient_id_test_overall, processed_tes], axis=1)\n",
    "\n",
    "tune_id_train = get_match_id(patient_id_train_overall, patient_id_train)\n",
    "tune_id_valid = get_match_id(patient_id_train_overall, patient_id_valid)\n",
    "processed_tr_tune = processed_tr.iloc[tune_id_train]\n",
    "processed_val_tune = processed_tr.iloc[tune_id_valid]\n",
    "\n",
    "processed_tr.to_csv(\"tr_z_2omics.csv\", index=False)\n",
    "processed_tr_tune.to_csv(\"tune_tr_z_2omics.csv\", index=False)\n",
    "processed_val_tune.to_csv(\"tune_val_z_2omics.csv\", index=False)\n",
    "processed_tes.to_csv(\"tes_z_2omics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAE",
   "language": "python",
   "name": "vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
